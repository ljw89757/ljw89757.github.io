<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="愚蠢的zzz侠">
<meta property="og:type" content="website">
<meta property="og:title" content="睿智的ljw侠">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="睿智的ljw侠">
<meta property="og:description" content="愚蠢的zzz侠">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Jiawei Li">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>睿智的ljw侠</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">睿智的ljw侠</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/02/03/13-DeepSeek%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="Jiawei Li">
      <meta itemprop="description" content="愚蠢的zzz侠">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="睿智的ljw侠">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/03/13-DeepSeek%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">13-DeepSeek总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-02-03 11:49:05" itemprop="dateCreated datePublished" datetime="2025-02-03T11:49:05+08:00">2025-02-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-02-05 10:15:40" itemprop="dateModified" datetime="2025-02-05T10:15:40+08:00">2025-02-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h5 id="1-参考"><a href="#1-参考" class="headerlink" title="1. 参考"></a>1. 参考</h5><ul>
<li><p>DeepSeek-V3技术报告：<a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf">DeepSeek-V3&#x2F;DeepSeek_V3.pdf at main · deepseek-ai&#x2F;DeepSeek-V3 · GitHub</a></p>
</li>
<li><p>DeepSeek-R1技术报告：<a target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf">DeepSeek-R1&#x2F;DeepSeek_R1.pdf at main · deepseek-ai&#x2F;DeepSeek-R1 · GitHub</a></p>
</li>
<li><p>DeepSeekMath：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.03300">[2402.03300] DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</a></p>
</li>
<li><p>权重（大小足有671B，FP8精度）：<a target="_blank" rel="noopener" href="https://huggingface.co/deepseek-ai/DeepSeek-V3-Base">deepseek-ai&#x2F;DeepSeek-V3-Base · Hugging Face</a></p>
</li>
<li><p>【论文解读】DeepSeek-V3技术报告 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/14988009150">https://zhuanlan.zhihu.com/p/14988009150</a></p>
</li>
<li><p>【论文解读】DeepSeek-R1：通过强化学习提升LLM推理能力 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/19551355661">https://zhuanlan.zhihu.com/p/19551355661</a></p>
</li>
<li><p>【论文解读】DeepSeekMath：用GRPO改进PPO <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/14574329458">https://zhuanlan.zhihu.com/p/14574329458</a></p>
</li>
<li><p>八个问题，带你零基础了解DeepSeek <a target="_blank" rel="noopener" href="https://news.qq.com/rain/a/20250202A05WKP00">https://news.qq.com/rain/a/20250202A05WKP00</a></p>
</li>
</ul>
<hr>
<h5 id="2-背景"><a href="#2-背景" class="headerlink" title="2. 背景"></a>2. 背景</h5><p><img src="https://inews.gtimg.com/news_bt/Ov9p60kvt5U-wTjM_moXxGc6mmckdZzqW7VPC58iC7XxcAA/641" alt="图片"></p>
<p>DeepSeek已经发布13个大模型，并且都已开源。</p>
<p><img src="https://inews.gtimg.com/news_bt/OUv3cR4Dkjq6H4oKKtczoIWQcAJDzwN6ZoilBtonqCRbcAA/641"></p>
<p>最近引起全世界广泛关注的模型，主要是自研通用大模型 DeepSeek-V3、推理模型 DeepSeek-R1 。（DeepSeek-V3 对标GPT-4o，DeepSeek-R1对标o1）。</p>
<ul>
<li><p>DeepSeek-V3 是一个通用模型，日常常见的问题，都可以尝试使用 V3。</p>
</li>
<li><p>DeepSeek - R1 是一个推理模型，擅长处理复杂、需要多步思考的问题，适合做深度研究、解决代码问题、数学问题。</p>
</li>
</ul>
<p><img src="https://inews.gtimg.com/news_bt/O4s96pmSE_kkUf1hUEIGG1-brd1j22JL7JaFKRTR84aeQAA/641"></p>
<p>目前Web和APP均免费。</p>
<ul>
<li><p>Web 端直接通过访问网址（<a target="_blank" rel="noopener" href="https://chat.deepseek.com/%EF%BC%89%E5%AF%B9%E8%AF%9D%E3%80%82%E5%9C%A8%E5%AF%B9%E8%AF%9D%E6%A1%86%E7%9A%84%E5%B7%A6%E4%B8%8B%E8%A7%92%E4%BD%8D%E7%BD%AE%EF%BC%8C%E5%8F%AF%E4%BB%A5%E9%80%89%E6%8B%A9%E6%98%AF%E5%90%A6%E5%BC%80%E5%90%AF%E2%80%9C%E6%B7%B1%E5%BA%A6%E6%80%9D%E8%80%83%E2%80%9D%E6%A8%A1%E5%BC%8F%E3%80%82%E5%A6%82%E6%9E%9C%E5%8B%BE%E9%80%89%EF%BC%8C%E4%BC%9A%E4%BD%BF%E7%94%A8">https://chat.deepseek.com/）对话。在对话框的左下角位置，可以选择是否开启“深度思考”模式。如果勾选，会使用</a> DeepSeek-R1 模型；如不勾选，则默认使用 DeepSeek-V3 。</p>
</li>
<li><p>App 直接在应用商店中搜索“DeepSeek”即可。在APP端，可以选择同时使用联网和推理功能。</p>
</li>
</ul>
<p>也可以通过多种渠道调用 DeepSeek 的API:</p>
<ol>
<li><p>DeepSeek开发者平台：访问 DeepSeek 控制台</p>
<p><a target="_blank" rel="noopener" href="https://platform.deepseek.com/%EF%BC%8C%E6%B3%A8%E5%86%8C%E7%99%BB%E5%BD%95%E5%B9%B6%E8%B4%AD%E4%B9%B0%E8%8E%B7%E5%8F%96%E7%9B%B8%E5%BA%94%E7%9A%84%E5%AF%86%E9%92%A5%E3%80%82%EF%BC%88%E4%B8%8D%E8%BF%87%EF%BC%8C%E8%BF%91%E6%9C%9F%E8%AF%A5%E5%B9%B3%E5%8F%B0%E6%AD%A3%E5%9C%A8%E7%BB%B4%E6%8A%A4%E5%BD%93%E4%B8%AD%EF%BC%89">https://platform.deepseek.com/，注册登录并购买获取相应的密钥。（不过，近期该平台正在维护当中）</a></p>
</li>
<li><p>英伟达 NIM 微服务：</p>
<p><a target="_blank" rel="noopener" href="https://build.nvidia.com/deepseek-ai/deepseek-r1%EF%BC%8C%E6%94%AF%E6%8C%81API%E8%B0%83%E7%94%A8">https://build.nvidia.com/deepseek-ai/deepseek-r1，支持API调用</a> DeepSeek-R1，需要使用邮箱注册账号。</p>
</li>
<li><p>微软 Azure：</p>
<p><a target="_blank" rel="noopener" href="https://ai.azure.com,微软/">https://ai.azure.com，微软</a> Azure 可以通过聊天操场，部署DeepSeek-R1，创建一个聊天机器人。</p>
</li>
<li><p>亚马逊 AWS：</p>
<p><a target="_blank" rel="noopener" href="https://aws.amazon.com/cn/blogs/aws/deepseek-r1-models-now-available-on-aws%EF%BC%8CDeepSeek-R1">https://aws.amazon.com/cn/blogs/aws/deepseek-r1-models-now-available-on-aws，DeepSeek-R1</a> 现已在 Amazon Bedrock Marketplace 和 Amazon SageMaker JumpStart 中推出，还可以在 Amazon Bedrock Custom Model Import 和 Amazon EC2 实例来使用 DeepSeek-R1-Distill 模型。</p>
</li>
<li><p>硅基流动 SiliconCloud ：</p>
<p><a target="_blank" rel="noopener" href="https://siliconflow.cn/zh-cn/models">https://siliconflow.cn/zh-cn/models</a> ，上线了基于华为云昇腾云服务的 DeepSeek-V3、DeepSeek-R1，开发者可以直接调用 SiliconCloud API，价格与 DeepSeek 官方优惠期价格保持一致。</p>
</li>
<li><p>此外，Cerebras、Groq 也可以调用 DeepSeek-R1 的 API。</p>
</li>
</ol>
<hr>
<h5 id="3-DeepSeek的优势"><a href="#3-DeepSeek的优势" class="headerlink" title="3. DeepSeek的优势"></a>3. DeepSeek的优势</h5><p>特点：</p>
<ul>
<li><p>性能优秀：这两款模型的性能接近甚至在某些场景超越了“公认”的全球标杆公司OpenAI的最好产品</p>
</li>
<li><p>结合应用：模型发布后，上线DeepSeek的Web&#x2F;APP，可切身体验模型效果。</p>
</li>
<li><p>训练成本低，产品性价比高</p>
<ul>
<li><p>根据 DeepSeek 的官方技术报告，V3 的训练成本仅 557.6 万美元。OpenAI 虽然没有官方公布过 4o 的训练成本，但据OpenAI CEO Sam Altman 透露，GPT-4 的训练总计花费了约1亿美元。</p>
</li>
<li><p>V3 仅使用了 2048 个 H800 GPU、花费2个月训练完成，使用GPU的数量和训练时长颠覆传统认知。</p>
</li>
<li><p>R1 和 V3 都可以在 DeepSeek 官网上免费使用；API 的定价中，R1 输入部分的价格是 o1 的 1.82%，输出部分是 o1 的 3.65%；V3 输入部分的价格是 GPT-4o 的 1.12%，输出部分是 GPT-4o 的 2.8%。</p>
</li>
</ul>
</li>
<li><p>技术创新：DeepSeek-R1 的训练模式颠覆了常规认知。DeepSeek-R1 是首个验证了仅通过 RL（强化学习）无需 SFT （监督微调） 就能得到大幅推理能力增强和涌现的模型。这种训练方式大幅降低了数据标注成本，简化了训练流程，整体训练成本也得到了降低。</p>
</li>
<li><p>开源：目前没有其他在性能上对标 GPT-4o 和 o1 的开源模型。OpenAI 旗下主打的核心模型都没有开源，用户要使用必须通过APP或 API 调用。</p>
</li>
</ul>
<hr>
<h5 id="4-目前形势"><a href="#4-目前形势" class="headerlink" title="4. 目前形势"></a>4. 目前形势</h5><ul>
<li><p>中国AI公司做出真正的创新，美国科技大厂担心失去领先地位。</p>
<ul>
<li><p>在此之前，模型层面的技术革新虽然也并非罕见，但都是美国模型厂商率先推出、其他厂商跟进验证的节奏。这一次 DeepSeek 走到了前面。</p>
</li>
<li><p>DeepSeek 在模型训练和架构上都有创新，能够显著降低推理阶段的成本、提高效率。长期以来，AI发展依赖于计算能力的积累，可以说是超大规模者之间的竞赛。对比美国的竞争者，DeepSeek的创新实现了训练成本和使用价格上数量级的减少，美国公司领先市场的重要优势被削弱了。</p>
</li>
</ul>
</li>
<li><p>开源：生态若能星火燎原，将抢占美国公司市场。DeepSeek 的 R1 不仅通过技术报告公开了训练过程，还开源了模型的权重。DeepSeek的推理模型拥有高性能和低价格，使得开发者能将其用于越来越多的场景。最近，微软、英伟达、AWS都纷纷接入DeepSeek-R1。</p>
</li>
<li><p>大模型相关的美国科技股受到巨大冲击。英伟达股价大跌，似乎暗示了 DeepSeek 的真实威胁。因为DeepSeek 的路线一定程度上说明，无需最强算力也能训练出高性能大模型，而且 DeepSeek 把高性能模型开源的路线可能让更多公司放弃训练模型，冲击了英伟达核心算力产品（GPU）的需求，影响股价。并且，市场担忧 DeepSeek 的成功冲击 OpenAI 等美国重点科技公司的市场前景，尤其是闭源模型方向。</p>
</li>
</ul>
<hr>
<h5 id="5-DeepSeek未来可能迭代方向"><a href="#5-DeepSeek未来可能迭代方向" class="headerlink" title="5. DeepSeek未来可能迭代方向"></a>5. DeepSeek未来可能迭代方向</h5><ul>
<li><p>未来的创新点可能还是会围绕着<strong>成本、性能</strong>这两大核心要素。</p>
</li>
<li><p>多模态能力补齐。</p>
<ul>
<li>除夕凌晨，DeepSeek新发布的 DeepSeek-Janus-Pro 模型是一个多模态模型，同时拥有视觉理解和视觉生成的能力。但 Janus 系列模型都是小参数量模型，如何通过 Janus 创新的模型框架训练出一个大参数量的多模态模型，可能是未来的重点之一。</li>
</ul>
</li>
<li><p>DeepSeek 在2025年1月终于推出面向 C 端用户的 APP 产品，可能未来会探索&#x2F;合作更多应用。</p>
</li>
</ul>
<hr>
<h5 id="6-可能会带来的影响"><a href="#6-可能会带来的影响" class="headerlink" title="6. 可能会带来的影响"></a>6. 可能会带来的影响</h5><ul>
<li><p>国内AI公司面临进一步限制</p>
<ul>
<li><p>芯片制裁可能更严重：DeepSeek 的低成本训练成果，可能会让美国进一步收缩可供出口的芯片型号。未来，国内模型厂商可用的 GPU 型号越来越少，代际越来越旧。</p>
</li>
<li><p>模型和应用层面的封锁也会随之而来：由于隐私、数据合规等质疑，一些国家和地区已经要求 DeepSeek 停止服务。Twitter上，一些 AI 科普类博主从之前的无脑捧吹 DeepSeek 的帖子，已经转变为教用户 “如何本地化部署一个 DeepSeek R1 来保护自己的数据” 这样的帖子。</p>
</li>
</ul>
</li>
<li><p>全球AI生态的竞争可能会被重塑</p>
<ul>
<li>DeepSeek 得到市场认可，一定程度上说明，算法效率、经济高效将成为未来竞争中的核心要素。DeepSeek 正推动 AI 行业从“算力军备竞赛”转向“算法效率战争”，AI技术进一步普惠化。那些以往以“算力为重”的公司将要重新审视自己的战略。</li>
</ul>
</li>
<li><p>硅谷巨头们急迫重新领先</p>
<ul>
<li>技术上进行革新、重新夺取领先地位的紧迫感，会笼罩着美国的科技巨头们。据称，目前 Google、Apple、Meta 等公司，已经纷纷开始深度研究 DeepSeek。尽快推出下一个代际的领先模型，是硅谷各家的当务之急。</li>
</ul>
</li>
</ul>
<hr>
<h5 id="7-可能面临的有利影响和发展方向"><a href="#7-可能面临的有利影响和发展方向" class="headerlink" title="7. 可能面临的有利影响和发展方向"></a>7. 可能面临的有利影响和发展方向</h5><p>有利影响：</p>
<ul>
<li><p>随着国际芯片制裁加剧，国内市场对国产GPU和AI芯片的需求将上升，有机会填补这一空白。</p>
</li>
<li><p>数据隐私和合规要求推动本地化部署，可提供定制化解决方案。</p>
</li>
<li><p>可优化算法与硬件的协同，提升整体性能。参与国产AI生态建设，推动从硬件到软件的自主可控。</p>
</li>
</ul>
<p>发展方向：提供定制化解决方案，针对数据隐私和合规需求，提供本地化部署支持。</p>
<hr>
<h5 id="8-技术细节"><a href="#8-技术细节" class="headerlink" title="8. 技术细节"></a>8. 技术细节</h5><h6 id="8-1-DeepSeek-V3-使用-MoE-架构："><a href="#8-1-DeepSeek-V3-使用-MoE-架构：" class="headerlink" title="8.1 DeepSeek-V3 使用 MoE 架构："></a>8.1 DeepSeek-V3 使用 MoE 架构：</h6><p>MoE (Mixture-of-Experts) 模型，即混合专家模型，是一种将多个小型专家模型组合起来，共同完成任务的架构。每个专家模型只处理部分输入，从而提高模型的效率和扩展性。</p>
<p>DeepSeek-V3 使用 MoE 架构的原因主要有以下几点：</p>
<ul>
<li>提高模型容量：MoE 可以显著增加模型的参数数量，而无需像稠密模型那样增加计算量。这使得模型可以学习更复杂的模式和关系，提高模型的性能。</li>
<li>降低训练成本：虽然 MoE 模型的总参数量很大，但每次激活的参数量却很小，从而减少了训练所需的计算资源。</li>
<li>提高推理效率： 在推理时，只有部分专家被激活，从而降低了推理的计算成本。</li>
</ul>
<hr>
<h6 id="8-2-DeepSeek-V3-使用Multi-Head-Latent-Attention-MLA"><a href="#8-2-DeepSeek-V3-使用Multi-Head-Latent-Attention-MLA" class="headerlink" title="8.2 DeepSeek-V3 使用Multi-Head Latent Attention (MLA)"></a>8.2 DeepSeek-V3 使用Multi-Head Latent Attention (MLA)</h6><p>Multi-Head Latent Attention (MLA)，即多头潜在注意力机制，旨在减少推理阶段的内存占用。MLA 和传统的 MHA 的主要区别在于：</p>
<ul>
<li>KV 缓存：在传统的 MHA 中，每个 token 的 Key 和 Value 向量都需要缓存起来，这在长文本生成中会占用大量的显存。而 MLA 通过低秩压缩技术，将 Key 和 Value 向量压缩成低维度的潜在向量，只需缓存压缩后的表示，从而显著减少 KV 缓存的内存占用。</li>
<li>通俗类比：想象在听一场演讲，传统的注意力机制需要记住每个时间点的所有细节（就像记录每一秒的录音）。而 MLA 则只提取关键信息（就像只记录每个重点句子），这样需要记忆的信息就大大减少了。</li>
</ul>
<p><img src="/2025/02/03/13-DeepSeek%E6%80%BB%E7%BB%93/2025-02-04-00-49-49-image.png"></p>
<hr>
<h6 id="8-3-DeepSeek-V3-的无辅助损失负载均衡策略"><a href="#8-3-DeepSeek-V3-的无辅助损失负载均衡策略" class="headerlink" title="8.3 DeepSeek-V3 的无辅助损失负载均衡策略"></a>8.3 DeepSeek-V3 的无辅助损失负载均衡策略</h6><p>在 MoE 模型中，如果专家负载不均衡，会导致以下问题：</p>
<ul>
<li>路由崩溃：某些专家可能会被过度使用，而其他专家则被闲置。</li>
<li>计算效率降低：过度使用的专家会成为性能瓶颈，而闲置的专家则浪费了计算资源。</li>
</ul>
<p>传统 MoE 模型为了实现专家间的负载均衡，通常引入辅助损失。但辅助损失会对模型的主要优化目标产生干扰，可能导致性能下降。为了解决这个问题，DeepSeek-V3 提出了无辅助损失的负载均衡策略。该策略的核心思想是：</p>
<ol>
<li>引入偏置项：为每个专家引入一个偏置项，并将这个偏置项添加到亲和度得分中，从而影响路由决策。</li>
<li>动态调整偏置项：在训练过程中，如果一个专家被过度使用，则减小其偏置项；如果一个专家被闲置，则增大其偏置项。这样，可以动态调整专家负载，使其达到均衡。</li>
<li>不使用辅助损失：偏置项只用于路由，而不影响最终的门控值计算，从而避免了传统辅助损失对模型性能的损害。</li>
</ol>
<p>类比： 想象一下你在一个餐厅里，有多个厨师。如果顾客都点同样的菜，那么只有一个厨师会很忙，而其他厨师则没事做。为了解决这个问题，你可以告诉顾客：「今天点这道菜可以打折」，或者「点其他菜可以更快上菜」。这样，就可以引导顾客点不同的菜，让所有厨师都忙起来。DeepSeek-V3 的无辅助损失负载均衡策略就类似于这个引导顾客点不同菜的策略。</p>
<hr>
<h6 id="8-4-DeepSeek-V3-使用-Multi-Token-Prediction-MTP-提高模型性能"><a href="#8-4-DeepSeek-V3-使用-Multi-Token-Prediction-MTP-提高模型性能" class="headerlink" title="8.4 DeepSeek-V3 使用 Multi-Token Prediction (MTP) 提高模型性能"></a>8.4 DeepSeek-V3 使用 Multi-Token Prediction (MTP) 提高模型性能</h6><p>在传统的语言模型训练中，模型通常只预测下一个标记。MTP 则是在每个位置上，让模型预测多个未来的标记。</p>
<ul>
<li><p>实现方法：引入了多个预测模块，每个模块负责预测不同深度（未来第几个）的标记。在训练过程中，对每个深度的预测计算损失，然后将这些<strong>损失平均</strong>，作为整体的 MTP 损失。</p>
</li>
<li><p>好处：增加训练信号：通过预测多个 token，模型可以获得更密集的训练信号，提高数据效率。增强预规划能力：MTP 可以帮助模型更好地预先规划未来 token 的表示，使其更好地捕捉长距离依赖关系，从而提高模型的性能。</p>
</li>
</ul>
<hr>
<h6 id="8-5-DeepSeek-V3-使用-FP8-训练混合精度训练"><a href="#8-5-DeepSeek-V3-使用-FP8-训练混合精度训练" class="headerlink" title="8.5 DeepSeek-V3 使用 FP8 训练混合精度训练"></a>8.5 DeepSeek-V3 使用 FP8 训练混合精度训练</h6><p>在深度学习训练中，使用低精度浮点数（如 FP16、FP8）可以降低计算和存储需求，提高训练速度。但低精度可能导致数值不稳定和模型性能下降。</p>
<ul>
<li><p>解决方案：</p>
<ul>
<li><p>精细量化策略。细粒度量化：对张量进行小块划分（如 1×128 或 128×128），对每个小块单独计算缩放因子，进行量化，减少了量化误差带来的影响。</p>
</li>
<li><p>提高积累精度。增加乘加运算的精度：在进行矩阵乘法累加时，将部分结果提升到更高精度（如 FP32）进行积累，减少了因低精度引入的误差。</p>
</li>
<li><p>混合精度训练框架。保留关键操作的高精度：对于敏感的操作，如嵌入层、归一化层等，仍然使用高精度计算，确保训练的稳定性。</p>
</li>
</ul>
</li>
<li><p>DeepSeek-V3 使用 FP8 训练的主要原因是：</p>
<ul>
<li><p>加速训练：FP8 格式可以加速 GEMM (General Matrix Multiplication) 等核心计算操作，从而提高训练速度。</p>
</li>
<li><p>减少内存使用：FP8 格式可以显著减少内存占用，使得在有限的显存中训练更大的模型成为可能。</p>
</li>
<li><p>突破硬件限制：目前 NVIDIA H100 及以上的 GPU 已经对 FP8 有了较好的支持，而 DeepSeek-V3 使用了 FP8 混合精度训练，使其可以更好地利用硬件性能。</p>
</li>
</ul>
</li>
</ul>
<hr>
<h6 id="8-6-DeepSeek-V3-的-DualPipe-算法解决通信瓶颈"><a href="#8-6-DeepSeek-V3-的-DualPipe-算法解决通信瓶颈" class="headerlink" title="8.6 DeepSeek-V3 的 DualPipe 算法解决通信瓶颈"></a>8.6 DeepSeek-V3 的 DualPipe 算法解决通信瓶颈</h6><p>DualPipe 算法是 DeepSeek-V3 中用于解决通信瓶颈的一种高效流水线并行算法。它的核心思想是通过重叠前向和后向计算与通信，从而减少流水线气泡，提高训练效率。</p>
<p>具体来说，DualPipe 算法：</p>
<ol>
<li>双向流水线：同时从流水线的两端输入 micro-batch，实现双向并行计算。</li>
<li>计算-通信重叠：将每个 chunk 分成多个部分，并调整 GPU SM 用于通信和计算的比例，使得计算和通信可以相互重叠。</li>
<li>减少流水线气泡： 通过双向流水线和计算-通信重叠，减少了流水线中的等待时间，从而提高了训练效率。</li>
</ol>
<p>类比：可以将 DualPipe 算法想象成一个生产线。传统的流水线是按顺序一个一个地处理产品，而 DualPipe 算法是同时从两个方向处理产品，并让不同环节同时进行，从而提高了生产效率。</p>
<hr>
<h6 id="8-7-DeepSeek-V3-与传统的知识蒸馏的不同"><a href="#8-7-DeepSeek-V3-与传统的知识蒸馏的不同" class="headerlink" title="8.7 DeepSeek-V3 与传统的知识蒸馏的不同"></a>8.7 DeepSeek-V3 与传统的知识蒸馏的不同</h6><p>DeepSeek-V3 使用了一种特殊的知识蒸馏方法，从 DeepSeek-R1 模型中提炼推理能力。与传统的知识蒸馏不同，DeepSeek-V3 的知识蒸馏：</p>
<ul>
<li>重点在于推理模式：不是简单地模仿 R1 的输出，而是将 R1 的反思和验证模式融入到 DeepSeek-V3 中。</li>
<li>生成多样化的 SFT 数据：通过让 R1 生成带有反思和验证的响应，为 DeepSeek-V3 提供更高质量的 SFT 数据。</li>
<li>在强化学习中运用：在 RL 阶段，通过高温度采样生成融合了 R1 和原始数据的响应，使模型学习 R1 的推理模式。</li>
</ul>
<hr>
<h6 id="8-8-DeepSeek-V3-使用-tile-wise-和-block-wise-量化"><a href="#8-8-DeepSeek-V3-使用-tile-wise-和-block-wise-量化" class="headerlink" title="8.8 DeepSeek-V3 使用 tile-wise 和 block-wise 量化"></a>8.8 DeepSeek-V3 使用 <code>tile-wise</code> 和 <code>block-wise</code> 量化</h6><p><code>tile-wise</code> 和 <code>block-wise</code> 量化是用于提高 FP8 量化精度的两种细粒度量化方法：</p>
<ul>
<li>tile-wise 量化：对于激活值（activations），将 1xNe 的元素分组成一个 tile，然后在 tile 内进行缩放（scaling）。这里的 Ne 通常是 128，所以就是一个 1x128 的 tile。这意味着，对于每一个 token，每 128 个通道（channel）会被分成一组。</li>
<li>block-wise 量化：对于权重（weights），将 Ne x Ne 的元素分组成一个 block，然后在 block 内进行缩放。这里的 Ne 也通常是 128，所以就是一个 128x128 的 block。这意味着，每 128 个输入通道和 128 个输出通道会被分组成一个 block。</li>
</ul>
<p>这种细粒度的量化方法可以更好地适应激活值和权重中的异常值，提高量化的精度，从而使模型能够更有效地利用低精度的 FP8 格式进行训练。</p>
<p>类比：可以将 <code>tile-wise</code> 和 <code>block-wise</code> 量化想象成在打包货物时，不是把所有货物都放在一个大箱子里，而是将它们根据形状、大小等进行分类，然后分别打包。这样可以更好地利用空间，减少货物之间的挤压和碰撞。</p>
<hr>
<h6 id="8-9-DeepSeek-R1-Zero-研究纯强化学习（RL）在-LLM-推理能力上的应用"><a href="#8-9-DeepSeek-R1-Zero-研究纯强化学习（RL）在-LLM-推理能力上的应用" class="headerlink" title="8.9 DeepSeek-R1-Zero 研究纯强化学习（RL）在 LLM 推理能力上的应用"></a>8.9 DeepSeek-R1-Zero 研究纯强化学习（RL）在 LLM 推理能力上的应用</h6><p>直接在基础模型上应用强化学习，不使用任何 SFT 数据。探索 LLM 在纯 RL 环境下的自演化过程，使其自主发展推理能力。</p>
<ul>
<li><p>近年来，LLM 在各个领域都取得了显著进展，但推理能力仍有提升空间。</p>
</li>
<li><p>之前的研究大多依赖于大量的监督式微调（SFT）数据，但获取高质量的 SFT 数据成本高昂。</p>
</li>
<li><p>OpenAI 的 o1 系列模型通过增加思维链（Chain-of-Thought, CoT）推理过程的长度来提升推理能力，但如何有效进行测试时（test-time）扩展仍是开放问题。</p>
</li>
<li><p>一些研究尝试使用基于过程的奖励模型、强化学习和搜索算法来解决推理问题，但没有达到 OpenAI 的 o1 系列模型的通用推理性能水平。</p>
</li>
</ul>
<hr>
<h6 id="8-10-DeepSeek-R1-Zero-的「顿悟」时刻-aha-moment"><a href="#8-10-DeepSeek-R1-Zero-的「顿悟」时刻-aha-moment" class="headerlink" title="8.10 DeepSeek-R1-Zero 的「顿悟」时刻 aha moment"></a>8.10 DeepSeek-R1-Zero 的「顿悟」时刻 aha moment</h6><p>在大规模强化学习中，模型的「思考过程」会不断与最终的正确率奖励相互作用。当模型最初得出的答案并未得到较高奖励时，它会在后续的推理中「回头反省」，尝试补充或修正先前的思路，从而获得更高的奖励。随着强化学习的迭代，这种「主动回溯、推翻先前想法并重新推理」的行为逐渐巩固，便在输出中表现为所谓的「aha moment」。本质上，这是RL为模型「留出了」足够的思考和试错空间，当模型自行发现更优思路时，就会出现类似人类「恍然大悟」的瞬间。</p>
<p>这也展示了 RL 的强大潜力，它可以让模型在没有明确指导的情况下，自主学习并改进。</p>
<hr>
<h6 id="8-11-DeepSeek-R1相比DeepSeek-R1-Zero-做出的改进"><a href="#8-11-DeepSeek-R1相比DeepSeek-R1-Zero-做出的改进" class="headerlink" title="8.11 DeepSeek-R1相比DeepSeek-R1-Zero 做出的改进"></a>8.11 DeepSeek-R1相比DeepSeek-R1-Zero 做出的改进</h6><ul>
<li><p>引入冷启动数据：使用了数千条带详细推理过程（长CoT）的数据先做一次SFT，让模型初始时就具备一定可读性与写作风格。</p>
</li>
<li><p>分阶段RL：在推理收敛后，通过拒绝采样等手段获得更多优质监督样本，再进行SFT，再全场景RL，不断修正模型的正确性与通用能力。</p>
</li>
<li><p>语言一致性奖励：避免模型出现大量的拼写或中英文混杂，从而保证可读性。</p>
</li>
</ul>
<hr>
<h6 id="8-12-DeepSeek-R1-要使用冷启动数据"><a href="#8-12-DeepSeek-R1-要使用冷启动数据" class="headerlink" title="8.12 DeepSeek-R1 要使用冷启动数据"></a>8.12 DeepSeek-R1 要使用冷启动数据</h6><p>DeepSeek-R1 使用冷启动数据的主要目的是为了解决 DeepSeek-R1-Zero 在训练早期出现的训练不稳定问题。相比于直接在基础模型上进行 RL，使用少量的 SFT 数据进行冷启动，可以让模型更快地进入稳定训练阶段：</p>
<ul>
<li>可读性：冷启动数据使用更易于理解的格式，输出内容更适合人类阅读，避免了 DeepSeek-R1-Zero 输出的语言混合、格式混乱等问题。</li>
<li>潜在性能：通过精心设计冷启动数据的模式，可以引导模型产生更好的推理能力。</li>
<li>稳定训练：使用 SFT 数据作为起始点，可以避免RL 训练早期阶段的不稳定问题。</li>
</ul>
<hr>
<h6 id="8-13-DeepSeek-R1-的多阶段训练框架中每个阶段的侧重点"><a href="#8-13-DeepSeek-R1-的多阶段训练框架中每个阶段的侧重点" class="headerlink" title="8.13 DeepSeek-R1 的多阶段训练框架中每个阶段的侧重点"></a>8.13 DeepSeek-R1 的多阶段训练框架中每个阶段的侧重点</h6><ul>
<li><p>冷启动（Cold Start）：使用少量高质量的 CoT 数据对基础模型进行微调，作为 RL 训练的初始起点。侧重点是让模型掌握基本的 CoT 推理能力，并使模型的输出更具可读性。</p>
</li>
<li><p>推理导向的强化学习（Reasoning-oriented RL）：在冷启动模型的基础上进行 RL 训练，侧重点是提升模型在推理任务上的性能。在这个阶段，会引入语言一致性奖励，以减少推理过程中的语言混合问题。</p>
</li>
<li><p>拒绝采样和监督微调（Rejection Sampling and SFT）：使用上一阶段的 RL 模型进行拒绝采样，生成高质量的推理和非推理数据，并用这些数据对模型进行微调。侧重点是提升模型的综合能力，使其在写作、事实问答等多种任务上表现良好。</p>
</li>
<li><p>所有场景下的强化学习（RL for all scenarios）：在上一阶段 SFT 模型的基础上进行 RL 训练，侧重点是使模型在所有场景下都能表现良好，包括推理任务和非推理任务，并且保证模型的安全性和无害性。</p>
</li>
</ul>
<hr>
<h6 id="8-14-DeepSeekMath-Corpus-的构建过程，需要迭代式地收集数据"><a href="#8-14-DeepSeekMath-Corpus-的构建过程，需要迭代式地收集数据" class="headerlink" title="8.14 DeepSeekMath Corpus 的构建过程，需要迭代式地收集数据"></a>8.14 DeepSeekMath Corpus 的构建过程，需要迭代式地收集数据</h6><p>迭代式地收集数据可以帮助不断优化 FastText 模型，从而发现更多高质量的数学网页。</p>
<ul>
<li>第一轮，使用 OpenWebMath 作为种子数据训练了一个 FastText 模型。但是这个模型只学到了一部分数学网页的特征，还有很多数学网页没有被识别出来。</li>
<li>为了让 FastText 模型更强大，分析第一轮收集到的网页的来源，找到一些可能包含更多数学网页的网站，比如 <a href="https://link.zhihu.com/?target=http://mathoverflow.net">http://mathoverflow.net</a>。然后，人工标注这些网站中的数学网页，将他们加入到种子数据中，用新的种子数据训练新的 FastText 模型，这个新模型就可以识别更多的数学网页。</li>
<li>通过多轮迭代，FastText 模型越来越强大，可以找到更多高质量的数学网页。就像我们学习一个新知识一样，先从简单的概念入手，然后不断深入，才能全面掌握。</li>
</ul>
<hr>
<h6 id="8-15-DeepSeekMath-Base-从-DeepSeek-Coder-Base-模型开始进行数学预训练"><a href="#8-15-DeepSeekMath-Base-从-DeepSeek-Coder-Base-模型开始进行数学预训练" class="headerlink" title="8.15 DeepSeekMath-Base 从 DeepSeek-Coder-Base 模型开始进行数学预训练"></a>8.15 DeepSeekMath-Base 从 DeepSeek-Coder-Base 模型开始进行数学预训练</h6><p>使用 DeepSeek-Coder-Base-v1.5 7B 作为初始化模型，并在 DeepSeekMath Corpus 上进行预训练。因为发现代码训练有助于提升模型的推理能力，特别是数学推理能力。具体来说，代码训练可以让模型更好地理解逻辑和结构化的思维，这对于解决数学问题至关重要。先进行代码训练，再进行数学训练，可以获得更好的数学推理能力。</p>
<ul>
<li>逻辑思维：代码的执行需要精确的逻辑，这与数学推理非常相似。代码训练可以帮助模型学习和掌握逻辑思维的能力，从而更好地解决数学问题。</li>
<li>结构化思维：代码具有严谨的结构，这与数学证明的结构类似。代码训练可以让模型更好地理解和运用结构化思维，这有助于模型更好地分析和解决数学问题。</li>
<li>抽象能力：代码中的变量和函数是对现实世界事物的抽象，这与数学中的符号和公式类似。代码训练可以帮助模型提高抽象能力，从而更好地理解数学概念和公式。</li>
<li>解决问题的能力：代码的目的是解决问题，数学的目的是解决数学问题，这个过程都需要很强的解决问题的能力，代码训练可以帮助模型提高解决问题的能力，从而更好地解决数学问题。</li>
</ul>
<hr>
<h6 id="8-16-DeepSeekMath-RL-通过-GRPO-强化学习进一步优化的模型"><a href="#8-16-DeepSeekMath-RL-通过-GRPO-强化学习进一步优化的模型" class="headerlink" title="8.16 DeepSeekMath-RL 通过 GRPO 强化学习进一步优化的模型"></a>8.16 DeepSeekMath-RL 通过 GRPO 强化学习进一步优化的模型</h6><p>GRPO 算法减少计算资源消耗。GRPO 的核心在于它避免了像 PPO 那样训练一个额外的 value 模型，而是通过 group scores 来估计 baseline。</p>
<ul>
<li><p>PPO 需要训练一个额外的 value 模型来估计状态的价值，这个 value 模型通常和 policy 模型规模相当，所以训练过程很耗费计算资源。</p>
</li>
<li><p>GRPO 则不同，它不需要训练额外的 value 模型。对于每个问题，GRPO 会从 policy 模型中采样多个输出，然后将这些输出的奖励值进行归一化，并以此作为 baseline。这样，GRPO 可以省去训练 value 模型的开销，从而大大减少计算资源的消耗。</p>
</li>
<li><p>更形象地说，PPO 要给每个学生都找一个辅导老师（value model），而 GRPO 是让学生之间互相评价（group score），然后进行自我调整，显然后者更节省资源。</p>
</li>
</ul>
<p><img src="/2025/02/03/13-DeepSeek%E6%80%BB%E7%BB%93/2025-02-04-01-33-36-image.png"></p>
<hr>
<h6 id="8-17-RL-的未来方向"><a href="#8-17-RL-的未来方向" class="headerlink" title="8.17 RL 的未来方向"></a>8.17 RL 的未来方向</h6><p>总的来说，未来的研究方向将集中于如何让 RL 更有效地利用数据，更可靠地学习，以及更准确地评估。</p>
<ul>
<li><p>数据源：</p>
<ul>
<li><p>探索更多样的训练数据，包括分布外的问题和高级解码策略；</p>
</li>
<li><p>优化模型探索效率。</p>
</li>
</ul>
</li>
<li><p>算法：</p>
<ul>
<li>开发更鲁棒的 RL 算法，以应对训练信号中的噪声，比如使用弱监督方法。</li>
</ul>
</li>
<li><p>奖励函数：</p>
<ul>
<li><p>提高奖励函数的泛化能力，使其能够处理分布外问题和高级解码输出；</p>
</li>
<li><p>反映奖励函数的不确定性，将其与弱监督方法连接起来；</p>
</li>
<li><p>构建高质量的过程奖励模型，为推理过程提供细粒度的训练信号。</p>
</li>
</ul>
</li>
</ul>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/01/27/12-Docker%E5%AE%B9%E5%99%A8%E4%B8%AD%E8%A7%A3%E5%86%B3SharedMemory%E4%B8%8D%E8%B6%B3%E9%97%AE%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="Jiawei Li">
      <meta itemprop="description" content="愚蠢的zzz侠">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="睿智的ljw侠">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/27/12-Docker%E5%AE%B9%E5%99%A8%E4%B8%AD%E8%A7%A3%E5%86%B3SharedMemory%E4%B8%8D%E8%B6%B3%E9%97%AE%E9%A2%98/" class="post-title-link" itemprop="url">12-Docker容器中解决Shared Memory不足问题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-01-27 11:49:05 / 修改时间：14:45:51" itemprop="dateCreated datePublished" datetime="2025-01-27T11:49:05+08:00">2025-01-27</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <hr>
<h5 id="1-参考"><a href="#1-参考" class="headerlink" title="1, 参考"></a>1, 参考</h5><ul>
<li><a target="_blank" rel="noopener" href="https://gitee.com/ascend/ascend-docker-image/tree/dev/mindie#%E5%90%AF%E5%8A%A8%E5%AE%B9%E5%99%A8">启动容器</a></li>
</ul>
<h5 id="1-报错信息"><a href="#1-报错信息" class="headerlink" title="1. 报错信息"></a>1. 报错信息</h5><p>在使用 PyTorch 等深度学习框架时，可能会遇到以下错误：</p>
<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">RuntimeError:</span> DataLoader worker (pid X) <span class="built_in">is</span> killed <span class="keyword">by</span> signal: Bus <span class="keyword">error</span>. It <span class="built_in">is</span> possible that dataloader<span class="comment">&#x27;s workers are out of shared memory...</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>错误原因</strong></p>
</blockquote>
<blockquote>
<p>这个错误通常是由于容器的共享内存（<code>/dev/shm</code>）不足引起的，尤其在处理大规模数据加载或多线程操作时容易出现。</p>
</blockquote>
<hr>
<h5 id="2-解决方案"><a href="#2-解决方案" class="headerlink" title="2. 解决方案"></a>2. 解决方案</h5><p>增大共享内存大小 (<code>--shm-size</code>)</p>
<p>在使用 Docker 启动容器时，通过 <code>--shm-size</code> 参数增大共享内存。例如，将共享内存设置为 8GB：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --shm-size=8g ...</span><br></pre></td></tr></table></figure>

<p>可以使用以下命令查看容器的共享内存使用情况：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">df</span> -h /dev/shm</span><br></pre></td></tr></table></figure>

<hr>
<h5 id="3-操作步骤"><a href="#3-操作步骤" class="headerlink" title="3. 操作步骤"></a>3. 操作步骤</h5><p><strong>针对现有容器修改共享内存大小</strong></p>
<p>在 Docker 中，共享内存大小属于<strong>容器运行期配置</strong>，无法直接对已创建的容器进行修改。为了保存现有容器内容并重新配置共享内存，可以按照以下步骤进行。</p>
<ul>
<li>停止运行中的容器</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br><span class="line">docker stop &lt;容器ID&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>使用 <code>docker commit</code> 保存容器</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker commit &lt;容器ID&gt; &lt;new-image-name&gt;:&lt;tag&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>以新的共享内存大小启动容器</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">docker run -it -d --net=host --shm-size=8g \</span><br><span class="line">    --privileged \</span><br><span class="line">    --name &lt;new-container-name&gt; \</span><br><span class="line">    --device=/dev/davinci_manager \</span><br><span class="line">    --device=/dev/hisi_hdc \</span><br><span class="line">    --device=/dev/devmm_svm \</span><br><span class="line">    --device=/dev/davinciX \</span><br><span class="line">    -v /usr/local/Ascend/driver:/usr/local/Ascend/driver:ro \</span><br><span class="line">    -v /usr/local/sbin:/usr/local/sbin:ro \</span><br><span class="line">    -v /home/ljw:/home/ljw \</span><br><span class="line">    &lt;new-image-name&gt;:&lt;tag&gt; bash</span><br></pre></td></tr></table></figure>

<ul>
<li>验证共享内存大小</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">df</span> -h /dev/shm</span><br></pre></td></tr></table></figure>

<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/01/23/11-%E7%90%86%E8%A7%A3GridSample/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="Jiawei Li">
      <meta itemprop="description" content="愚蠢的zzz侠">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="睿智的ljw侠">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/23/11-%E7%90%86%E8%A7%A3GridSample/" class="post-title-link" itemprop="url">11-理解GridSample</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-01-23 15:10:11 / 修改时间：15:48:23" itemprop="dateCreated datePublished" datetime="2025-01-23T15:10:11+08:00">2025-01-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>在 PyTorch 中，&#96;&#96;torch.nn.functional.grid_sample&#96; 用于基于给定的“采样网格”（grid）对输入图像或特征图进行插值采样，从而实现对输入数据的空间变换。</p>
<hr>
<h5 id="1-参考"><a href="#1-参考" class="headerlink" title="1. 参考"></a>1. 参考</h5><ul>
<li><p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.grid_sample.html">torch.nn.functional.grid_sample &mdash; PyTorch 2.5 documentation</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/canncommercial/800/developmentguide/opdevg/Ascendcopdevg/atlas_ascendc_10_0001.html">Ascend C简介-Ascend C算子开发-算子开发-CANN商用版8.0.0开发文档-昇腾社区</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch/blob/main/torch/nn/functional.py">pytorch&#x2F;torch&#x2F;nn&#x2F;functional.py at main · pytorch&#x2F;pytorch · GitHub</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://gitee.com/ascend/DrivingSDK/blob/master/docs/api/context/grid_sampler2d_v2%5Bbeta%5D.md">docs&#x2F;api&#x2F;context&#x2F;grid_sampler2d_v2[beta].md · Ascend&#x2F;DrivingSDK - Gitee.com</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://gitee.com/ascend/DrivingSDK/blob/master/kernels/op_host/grid_sampler2d_v2.cpp">kernels&#x2F;op_host&#x2F;grid_sampler2d_v2.cpp · Ascend&#x2F;DrivingSDK - Gitee.com</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://gitee.com/ascend/DrivingSDK/blob/master/kernels/op_host/grid_sampler2d_v2_tiling.h">kernels&#x2F;op_host&#x2F;grid_sampler2d_v2_tiling.h · Ascend&#x2F;DrivingSDK - Gitee.com</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://gitee.com/ascend/DrivingSDK/blob/master/kernels/op_kernel/grid_sampler2d_v2.cpp">kernels&#x2F;op_kernel&#x2F;grid_sampler2d_v2.cpp · Ascend&#x2F;DrivingSDK - Gitee.com</a></p>
</li>
</ul>
<hr>
<h5 id="2-功能概述"><a href="#2-功能概述" class="headerlink" title="2. 功能概述"></a>2. 功能概述</h5><ul>
<li>核心逻辑：</li>
</ul>
<blockquote>
<p>根据输入的采样网格（grid），对输入特征图（input）进行插值操作，得到变换后的输出特征图（output）。</p>
</blockquote>
<ul>
<li>常见应用场景：</li>
</ul>
<blockquote>
<p><strong>空间变换网络（Spatial Transformer Networks, STN）</strong>：配合 <code>affine_grid</code>，构建端到端可微分的空间变换模块。</p>
<p><strong>图像变换和对齐</strong>：对输入图像进行旋转、缩放、平移等操作。</p>
<p><strong>任意插值采样</strong>：基于自定义网格从输入中提取特征。</p>
</blockquote>
<hr>
<h5 id="3-GradSample2D算子设计规格"><a href="#3-GradSample2D算子设计规格" class="headerlink" title="3. GradSample2D算子设计规格"></a>3. GradSample2D算子设计规格</h5><table>
<thead>
<tr>
<th>Classify</th>
<th>Name</th>
<th>Type</th>
<th>TypeRangeAll</th>
<th>Attr_Default_value</th>
<th>Format</th>
</tr>
</thead>
<tbody><tr>
<td>INPUT</td>
<td>input</td>
<td>tensor</td>
<td>fp32,fp16</td>
<td>-</td>
<td>ND</td>
</tr>
<tr>
<td>INPUT</td>
<td>grid</td>
<td>tensor</td>
<td>fp32,fp16</td>
<td>-</td>
<td>ND</td>
</tr>
<tr>
<td>INPUT</td>
<td>mode</td>
<td>string</td>
<td>-</td>
<td>bilinear</td>
<td></td>
</tr>
<tr>
<td>INPUT</td>
<td>padding_mode</td>
<td>string</td>
<td>-</td>
<td>zeros</td>
<td></td>
</tr>
<tr>
<td>INPUT</td>
<td>align_corners</td>
<td>bool</td>
<td>bool</td>
<td>FALSE</td>
<td></td>
</tr>
<tr>
<td>OUTPUT</td>
<td>output</td>
<td>tensor</td>
<td>fp32,fp16</td>
<td>-</td>
<td>ND</td>
</tr>
</tbody></table>
<ul>
<li><p><strong>输入与输出</strong>：</p>
<ul>
<li><p><code>input</code>：输入张量，形状为 (N, C, Hin, Win)</p>
</li>
<li><p><code>grid</code>：采样网格，形状为 (N, Hout, Wout, 2)，其中最后一个维度表示网格的二维坐标 (x, y)</p>
</li>
<li><p><code>mode</code>：插值方式，默认使用双线性插值。</p>
<ul>
<li>‘bilinear’：双线性插值（常用于大多数需要平滑变换的情景）。</li>
<li>‘nearest’：最邻近插值。</li>
<li>‘bicubic&#96;：双三次插值（仅支持 4D 输入）。</li>
</ul>
</li>
<li><p><code>padding_mode</code>：当网格坐标超出 [−1,1] 范围时的填充方式，默认用 0 填充。</p>
<ul>
<li>‘zeros’：超出范围的点直接赋 0。</li>
<li>‘border’：使用边界像素进行填充。</li>
<li>‘reflection’：将超出边界的坐标点“反射”回图像内部。</li>
</ul>
</li>
<li><p><code>align_corners</code>：控制 [−1,1] 坐标是否对齐到像素中心，默认为False。</p>
<ul>
<li>True：对齐到中心，适用于对某些几何变换有严格对齐需求的场景，但会带来分辨率依赖性。</li>
<li>False：对齐到边界，分辨率无关</li>
</ul>
</li>
<li><p><code>output</code>：输出采样之后的特征图，形状为 (N,C,Hout​,Wout​)。</p>
</li>
</ul>
</li>
<li><p><strong>核函数名称</strong>：grad_sample_2D_custom</p>
</li>
<li><p><strong>使用的主要接口</strong></p>
<ul>
<li>DataCopy：数据搬移接口</li>
<li>AllocTensor、FreeTensor：内存管理接口</li>
<li>EnQue、DeQue接口：Queue队列管理接口</li>
</ul>
</li>
<li><p><strong>算子实现文件名称</strong>：grad_sample_2D_custom.cpp</p>
</li>
<li><p>此函数通常与<code>affine_grid</code>一起使用以构建空间变换网络</p>
</li>
</ul>
<hr>
<h5 id="4-工作原理"><a href="#4-工作原理" class="headerlink" title="4. 工作原理"></a>4. 工作原理</h5><p>PyTorch 的 <code>grid_sample</code> 在 Forward 和 Backward 两个方向上都有清晰的实现逻辑。</p>
<ul>
<li><strong>Forward 过程</strong>：</li>
</ul>
<blockquote>
<p><strong>网格生成</strong>（配合 affine_grid）：</p>
<ul>
<li>将标准化网格坐标 [−1,1] 映射到输入图像坐标系。</li>
</ul>
<p><strong>采样</strong>：</p>
<ul>
<li><p>遍历输出图像的每个像素，根据 grid 提供的坐标从输入图像中插值。</p>
</li>
<li><p>插值方式由 mode 决定，支持双线性插值（bilinear）、最近邻插值（nearest）和双三次插值（bicubic）。</p>
</li>
</ul>
<p><strong>越界处理</strong>：</p>
<ul>
<li><p>对超出输入范围的坐标，根据 padding_mode 的设置进行填充。</p>
</li>
<li><p>常见的填充方式包括填充 0、使用边界值或反射回输入区域。</p>
</li>
</ul>
<p><strong>输出生成</strong>：</p>
<ul>
<li>按照采样结果生成新的特征图。</li>
</ul>
</blockquote>
<ul>
<li><strong>Backward 过程</strong>：</li>
</ul>
<blockquote>
<p><strong>对输入特征图的梯度计算</strong>：</p>
<ul>
<li>输出梯度根据插值权重反向传播到输入特征图。</li>
</ul>
<p><strong>对采样网格的梯度计算</strong>：</p>
<ul>
<li>输出梯度中的坐标相关部分反向传播到 grid，从而更新控制网格生成的参数。</li>
</ul>
</blockquote>
<hr>
<h5 id="5-代码实现细节-Python-前端接口"><a href="#5-代码实现细节-Python-前端接口" class="headerlink" title="5. 代码实现细节-Python 前端接口"></a>5. 代码实现细节-Python 前端接口</h5><p><strong>Python 前端 API</strong> (torch.nn.functional.grid_sample)</p>
<ul>
<li><p>位于<code>pytorch-main\torch\nn\functional.py</code>中</p>
</li>
<li><p>这是在 Python 里调用的函数接口，实际上会转到 C++&#x2F;CUDA 端去执行，参数检查、文档字符串等都在这里完成。</p>
</li>
<li><p>核心函数：</p>
<ul>
<li><p><strong>affine_grid</strong> 负责“创建”变换后每个输出像素在输入图像&#x2F;特征图中对应的坐标</p>
</li>
<li><p><strong>grid_sample</strong> 则根据这些坐标，在输入中插值得到最终变换后的输出。</p>
</li>
</ul>
</li>
</ul>
<p><img src="/2025/01/23/11-%E7%90%86%E8%A7%A3GridSample/2025-01-22-17-47-29-image.png"></p>
<blockquote>
<p>函数整体流程：</p>
<p><strong>affine_grid(theta, size, align_corners)</strong></p>
<ol>
<li><p>首先根据 size 计算输出网格的每个坐标点，其范围是 [−1,1]。</p>
</li>
<li><p>用仿射矩阵 θ 把这些标准坐标映射到输入图像坐标系中。</p>
</li>
<li><p>结果就是网格张量，每个位置告诉你“输出图像的这个像素，对应输入图像中的哪一点”。</p>
</li>
</ol>
<p><strong>grid_sample(input, grid, mode, padding_mode, align_corners)</strong></p>
<ol>
<li><p>遍历输出图像上的每个像素位置，从 grid 取到对应输入图上的坐标点。</p>
</li>
<li><p>根据 mode 所指定的插值方法，去输入图 input 中拿到像素值并插值。</p>
</li>
<li><p>如果坐标越界，就根据 padding_mode 做处理（填零、取边界或镜像）。</p>
</li>
<li><p>逐像素拼出采样后的输出图。</p>
</li>
</ol>
</blockquote>
<hr>
<h5 id="6-代码实现细节-C-CUDA-层实现"><a href="#6-代码实现细节-C-CUDA-层实现" class="headerlink" title="6. 代码实现细节-C++ &#x2F; CUDA 层实现"></a>6. 代码实现细节-C++ &#x2F; CUDA 层实现</h5><p><strong>C++&#x2F;ATen 层</strong>（主要逻辑入口）</p>
<p>在 <a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch">PyTorch GitHub 仓库</a> 中，核心的 grid_sample C++ 入口主要位于</p>
<ul>
<li><code>aten/src/ATen/native/GridSampler.cpp</code>（CPU 逻辑）</li>
<li><code>aten/src/ATen/native/cuda/GridSampler.cu</code>（CUDA 逻辑）</li>
<li>以及一些与调度、类型分发相关的文件。</li>
</ul>
<p><img src="/2025/01/23/11-%E7%90%86%E8%A7%A3GridSample/2025-01-23-14-32-34-image.png"></p>
<p><img src="/2025/01/23/11-%E7%90%86%E8%A7%A3GridSample/2025-01-23-14-33-27-image.png"></p>
<p><strong>forward&#x2F;backward 内核（kernel）</strong></p>
<ul>
<li><strong>Forward</strong>：在 GridSampler.cpp &#x2F; GridSampler.cu中，会分别实现 grid_sampler_2d_fwd_kernel、grid_sampler_3d_fwd_kernel 等（对应 2D、3D 输入）</li>
<li><strong>Backward</strong>：相应地，也会有 grid_sampler_2d_bwd_kernel、grid_sampler_3d_bwd_kernel 来计算反向传播时对输入图像及 grid 的梯度。</li>
</ul>
<p><strong>grid_sampler 在 ATen 层的函数签名</strong></p>
<ul>
<li><p>位于<code>aten\src\ATen\native\native_functions.yaml</code></p>
</li>
<li><p>声明了 grid_sampler 在 ATen 层的函数签名。</p>
</li>
<li><p>PyTorch 会根据这里的信息生成对外暴露的 C++&#x2F;Python 绑定。</p>
</li>
</ul>
<p><img src="/2025/01/23/11-%E7%90%86%E8%A7%A3GridSample/2025-01-23-14-51-40-image.png"></p>
<blockquote>
<p>主要流程：</p>
<p><strong>参数校验与维度检查</strong>：</p>
<ul>
<li><p>确保输入和网格的维度匹配。</p>
</li>
<li><p>检查 mode和 padding_mode 的合法性。</p>
</li>
</ul>
<p><strong>网格遍历与插值</strong>：</p>
<ul>
<li><p>遍历输出图像的每个像素，从网格中获取对应的输入坐标。</p>
</li>
<li><p>根据 mode 插值并生成输出像素值。</p>
</li>
</ul>
<p><strong>GPU 加速</strong>：</p>
<ul>
<li>根据输出尺寸，动态计算线程块和线程布局，调用 CUDA 内核实现并行处理。</li>
</ul>
</blockquote>
<hr>
<h5 id="7-主要逻辑"><a href="#7-主要逻辑" class="headerlink" title="7. 主要逻辑"></a>7. 主要逻辑</h5><p>PyTorch 在 C++&#x2F;CUDA 层的 grid_sample 实现大致可拆分为以下步骤：</p>
<ul>
<li><p><strong>维度解析与参数检查</strong></p>
<ul>
<li><p>检查输入 input 和 grid 的维度是否匹配（如 4D vs. 4D 网格，5D vs. 5D 网格等）。</p>
</li>
<li><p>检查插值模式（bilinear, nearest, bicubic）和边界模式（zeros, border, reflection）是否合法。</p>
</li>
<li><p>解析 align_corners 标志，后续计算插值坐标时需要用到。</p>
</li>
</ul>
</li>
<li><p><strong>确定并行策略</strong></p>
<ul>
<li><p>在 CPU 端通常使用 OpenMP 或者其他多线程方式并行遍历输出像素；</p>
</li>
<li><p>在 GPU（CUDA）端，会依据输出的尺寸，计算合适的线程块（block）和线程（thread）布局，并发起 kernel 调用。</p>
</li>
</ul>
</li>
<li><p><strong>在内核中遍历输出像素</strong></p>
<ul>
<li><p><strong>核心思路</strong>：对输出空间中的每个像素 (n,c,h,w)（或 3D 时 (n,c,d,h,w)）来说，先从 grid[n, h, w] 读取到输入特征图上的坐标 (x,y)，然后：</p>
<ol>
<li>根据插值模式 (mode) 计算该坐标对应的输入像素值。</li>
<li>如果坐标超出 [−1,1]，则按照 padding_mode（如 zeros&#x2F;border&#x2F;reflection）处理。</li>
<li>将得到的插值结果写入输出张量的相应位置。</li>
</ol>
</li>
<li><p>对于插值模式，“bilinear” 在 2D 场景下需要对 4 个邻近像素（左上、右上、左下、右下）做双线性加权，而 “nearest” 则直接取最近的像素，“bicubic” 做 4x4 neighborhood 的三次插值，3D 时思路类似，只是变为三线性、最邻近或三次插值。</p>
</li>
</ul>
</li>
<li><p><strong>反向传播</strong>（Backward）</p>
<ul>
<li><p>如果在计算梯度（即调用 .backward()），grid_sample 还需对输入 input 和 grid 计算梯度：</p>
<ol>
<li>对 input 的梯度：将来自输出像素的梯度<strong>按照插值权重</strong>反向加到输入对应像素上。</li>
<li>对 grid 的梯度：同样使用插值的偏导（∂x^&#x2F;∂x 等）将输出梯度中与坐标相关的部分累加到 grid。</li>
</ol>
</li>
<li><p>这就保证了在训练基于 grid_sample 的网络（例如空间变换网络 STN）时，θ（或任何定义 grid 的参数）可以通过可微分插值把梯度传回来。</p>
</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>核心算法</strong>就是<strong>对输出像素进行遍历</strong>，从网格中取到输入坐标，根据插值模式去输入张量读值并插值，然后写回输出；反向传播还要计算对输入和网格的梯度。</p>
</blockquote>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/01/23/10-AscendC%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%B0%83%E8%AF%95%E6%89%8B%E6%AE%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="Jiawei Li">
      <meta itemprop="description" content="愚蠢的zzz侠">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="睿智的ljw侠">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/23/10-AscendC%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%B0%83%E8%AF%95%E6%89%8B%E6%AE%B5/" class="post-title-link" itemprop="url">10-Ascend C环境下调试手段</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-01-23 11:49:05 / 修改时间：16:06:57" itemprop="dateCreated datePublished" datetime="2025-01-23T11:49:05+08:00">2025-01-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>下面是一份对「Ascend C」环境下常用调试手段的总结，涵盖从主机侧（Host）到核函数（Kernel）内的不同调试方法，以及日志排查与编译期调试信息输出等维度。可以根据实际需求自由组合使用。</p>
<hr>
<h5 id="1-host侧"><a href="#1-host侧" class="headerlink" title="1. host侧"></a>1. host侧</h5><ul>
<li>打印简单变量：直接使用 C++ <code>std::cout</code> 输出变量值，便于观察在 Host 端的数值变化：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; &quot;kernelHeight: &quot; &lt;&lt; kernelHeight &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure>

<ul>
<li>打印数组：编写一个通用的打印函数，循环输出数组元素：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">void printArray(const uint32_t* array, uint32_t size) &#123;</span><br><span class="line">    for (uint32_t i = 0; i &lt; size; ++i) &#123;</span><br><span class="line">        std::cout &lt;&lt; array[i] &lt;&lt; &quot; &quot;;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">        std::cout &lt;&lt; &quot;seqHeight: &quot;;</span><br><span class="line">        printArray(seqHeight, outHeight);</span><br><span class="line"></span><br><span class="line">        std::cout &lt;&lt; &quot;seqWidth: &quot;;</span><br><span class="line">        printArray(seqWidth, outWidth);</span><br></pre></td></tr></table></figure>

<hr>
<h5 id="2-Kernel-侧打印"><a href="#2-Kernel-侧打印" class="headerlink" title="2. Kernel 侧打印"></a>2. Kernel 侧打印</h5><p>在核函数（Kernel）内部，可以使用 <code>PRINTF</code> 函数输出常量或变量的调试信息。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int32_t a = heightSeq[0];</span><br><span class="line">PRINTF(&quot;【a %d 】  &quot;, a);</span><br></pre></td></tr></table></figure>

<hr>
<h5 id="3-Kernel-侧-DumpTensor"><a href="#3-Kernel-侧-DumpTensor" class="headerlink" title="3. Kernel 侧 DumpTensor"></a>3. Kernel 侧 DumpTensor</h5><p>当需要调试 <strong>GlobalTensor</strong> 或 <strong>LocalTensor</strong> 时，可使用 <code>DumpTensor</code> 输出中间张量的数据到文件。该功能需要在编译及配置文件中进行相应配置：</p>
<ul>
<li>编译时开关：在 <code>op_kernel/CMakeLists.txt</code> 中增加：</li>
</ul>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add_ops_compile_options(ALL OPTIONS -DASCENDC_DUMP)</span><br></pre></td></tr></table></figure>

<ul>
<li>配置文件：编辑 <code>/home/HwHiAiUser/FractionalMaxPool2dSample/FrameworkLaunch/AclNNInvocation/scripts/acl.json</code>，启用 <code>dump</code> 功能：</li>
</ul>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;dump&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;dump_path&quot;</span><span class="punctuation">:</span><span class="string">&quot;/home/HwHiAiUser/dump&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;dump_mode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;all&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;dump_debug&quot;</span><span class="punctuation">:</span> <span class="string">&quot;off&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;dump_op_switch&quot;</span><span class="punctuation">:</span> <span class="string">&quot;on&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>代码使用：在 Kernel 中调用</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DumpTensor(xLocal,73, 144);</span><br></pre></td></tr></table></figure>

<p>其中 <code>xLocal</code> 为需要 Dump 的张量句柄，<code>73</code>、<code>144</code> 可以是自定义标识，或张量的大小信息等参数。</p>
<hr>
<h5 id="4-查看日志"><a href="#4-查看日志" class="headerlink" title="4. 查看日志"></a>4. 查看日志</h5><p>有时可以通过日志查看关键信息或错误提示，常用日志路径为 <code>~/ascend/log/debug/plog</code>。可以使用 <code>grep</code> 进行过滤：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/ascend/log/debug/plog</span><br><span class="line">grep -rn <span class="string">&quot;error&quot;</span></span><br><span class="line">grep -rn <span class="string">&quot;errorStr&quot;</span></span><br></pre></td></tr></table></figure>

<hr>
<h5 id="5-编译器输出类型信息"><a href="#5-编译器输出类型信息" class="headerlink" title="5. 编译器输出类型信息"></a>5. 编译器输出类型信息</h5><p>如果需要在编译阶段确认某个宏或类型的值（如 <code>DTYPE_X</code>），可以通过预处理器和编译器的警告信息来实现。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#define STRINGIZE(x) #x</span><br><span class="line">#define TOSTRING(x) STRINGIZE(x)</span><br><span class="line"></span><br><span class="line">#pragma message(&quot;DTYPE_X is &quot; TOSTRING(DTYPE_X))</span><br></pre></td></tr></table></figure>

<p>编译器在编译时会在输出信息中提示 <code>DTYPE_X is xxx</code>，帮助我们在编译期确认类型或宏定义。</p>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="Jiawei Li">
      <meta itemprop="description" content="愚蠢的zzz侠">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="睿智的ljw侠">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">9-GirdSample算子预分析</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-01-22 15:10:11 / 修改时间：14:29:02" itemprop="dateCreated datePublished" datetime="2025-01-22T15:10:11+08:00">2025-01-22</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>整理了从环境安装、ONNX 导出、OM 模型转换、推理验证到算子支持查询的完整流程，并针对 GridSampler2D&#x2F;3D 的关键问题和解决思路进行了说明。</p>
<hr>
<h5 id="1-参考资料"><a href="#1-参考资料" class="headerlink" title="1. 参考资料"></a>1. 参考资料</h5><ul>
<li><p><a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/800alpha003/apiref/aolapi/atlasoxol_09_0071.html">GridSample-支持ONNX算子清单-AI框架算子支持清单-算子加速库接口-CANN社区版8.0.0.alpha003开发文档-昇腾社区</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/800alpha003/devaids/devtools/atc/atlasatc_16_0003.html#ZH-CN_TOPIC_0000002115847872__section1645421681020">快速入门-ATC工具-训练&amp;推理开发-CANN社区版8.0.0.alpha003开发文档-昇腾社区</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/800alpha003/apiref/aolapi/operatorlist_00095.html">规格清单-CANN算子规格说明-算子加速库接口-CANN社区版8.0.0.alpha003开发文档-昇腾社区</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://gitee.com/ascend/tools/tree/master/ais-bench_workload/tool/ais_bench">tools: Ascend tools - Gitee.com</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/800alpha003/devaids/devtools/opmodelquery/atlasopmodelquery_16_0003.html">操作指南-算子及模型速查工具-训练&amp;推理开发-CANN社区版8.0.0.alpha003开发文档-昇腾社区</a></p>
</li>
</ul>
<hr>
<h5 id="2-安装环境"><a href="#2-安装环境" class="headerlink" title="2. 安装环境"></a>2. 安装环境</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch&gt;=<span class="number">1.9</span> onnx==<span class="number">1.12</span><span class="number">.0</span> onnxruntime==<span class="number">1.14</span><span class="number">.0</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Opset v16</li>
</ul>
<hr>
<h5 id="3-导出-2D-GridSample-的-ONNX-模型"><a href="#3-导出-2D-GridSample-的-ONNX-模型" class="headerlink" title="3. 导出 2D GridSample 的 ONNX 模型"></a>3. 导出 2D GridSample 的 ONNX 模型</h5><ul>
<li>编写导出脚本 <code>export_grid_sample_onnx.py</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim export_grid_sample_onnx.py</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"><span class="keyword">import</span> onnxruntime <span class="keyword">as</span> ort</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GridSampleModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(GridSampleModel, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, </span><br><span class="line">                              kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, grid</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv(x)</span><br><span class="line"></span><br><span class="line">        out = F.grid_sample(</span><br><span class="line">            x, </span><br><span class="line">            grid, </span><br><span class="line">            mode=<span class="string">&#x27;bilinear&#x27;</span>, </span><br><span class="line">            padding_mode=<span class="string">&#x27;zeros&#x27;</span>, </span><br><span class="line">            align_corners=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    torch.manual_seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    model = GridSampleModel().<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    N, C, H, W = <span class="number">1</span>, <span class="number">1</span>, <span class="number">64</span>, <span class="number">64</span></span><br><span class="line">    x = torch.randn(N, C, H, W)</span><br><span class="line"></span><br><span class="line">    theta = torch.tensor([</span><br><span class="line">        [[<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],</span><br><span class="line">         [<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>]]</span><br><span class="line">    ], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">    grid = F.affine_grid(theta, size=(N, C, H, W), align_corners=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        out = model(x, grid)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;PyTorch output shape:&quot;</span>, out.shape)</span><br><span class="line"></span><br><span class="line">    onnx_model_path = <span class="string">&quot;grid_sample_model.onnx&quot;</span></span><br><span class="line">    torch.onnx.export(</span><br><span class="line">        model,</span><br><span class="line">        (x, grid),</span><br><span class="line">        onnx_model_path,</span><br><span class="line">        export_params=<span class="literal">True</span>,</span><br><span class="line">        opset_version=<span class="number">16</span>,</span><br><span class="line">        do_constant_folding=<span class="literal">True</span>,</span><br><span class="line">        input_names=[<span class="string">&quot;input_x&quot;</span>, <span class="string">&quot;input_grid&quot;</span>],</span><br><span class="line">        output_names=[<span class="string">&quot;output&quot;</span>],</span><br><span class="line">        dynamic_axes=&#123;</span><br><span class="line">            <span class="string">&quot;input_x&quot;</span>: &#123;<span class="number">0</span>: <span class="string">&quot;batch_size&quot;</span>, <span class="number">2</span>: <span class="string">&quot;height&quot;</span>, <span class="number">3</span>: <span class="string">&quot;width&quot;</span>&#125;,</span><br><span class="line">            <span class="string">&quot;input_grid&quot;</span>: &#123;<span class="number">0</span>: <span class="string">&quot;batch_size&quot;</span>, <span class="number">1</span>: <span class="string">&quot;grid_height&quot;</span>, <span class="number">2</span>: <span class="string">&quot;grid_width&quot;</span>&#125;,</span><br><span class="line">            <span class="string">&quot;output&quot;</span>: &#123;<span class="number">0</span>: <span class="string">&quot;batch_size&quot;</span>, <span class="number">2</span>: <span class="string">&quot;out_height&quot;</span>, <span class="number">3</span>: <span class="string">&quot;out_width&quot;</span>&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;ONNX model saved to: <span class="subst">&#123;onnx_model_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    onnx_model = onnx.load(onnx_model_path)</span><br><span class="line">    onnx.checker.check_model(onnx_model)</span><br><span class="line"></span><br><span class="line">    ort_sess = ort.InferenceSession(onnx_model_path)</span><br><span class="line"></span><br><span class="line">    x_np = x.cpu().numpy()</span><br><span class="line">    grid_np = grid.cpu().numpy()</span><br><span class="line"></span><br><span class="line">    onnx_out = ort_sess.run(</span><br><span class="line">        <span class="literal">None</span>,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;input_x&quot;</span>: x_np,</span><br><span class="line">            <span class="string">&quot;input_grid&quot;</span>: grid_np</span><br><span class="line">        &#125;</span><br><span class="line">    )[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;ONNX Runtime output shape:&quot;</span>, onnx_out.shape)</span><br><span class="line"></span><br><span class="line">    diff = np.mean(np.<span class="built_in">abs</span>(out.cpu().numpy() - onnx_out))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Mean absolute difference between PyTorch and ONNX outputs: <span class="subst">&#123;diff:<span class="number">.6</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<ul>
<li>运行导出脚本</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 export_grid_sample.py</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-12-06-25-image.png"></p>
<hr>
<h5 id="4-转换成om模型"><a href="#4-转换成om模型" class="headerlink" title="4. 转换成om模型"></a>4. 转换成om模型</h5><p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-12-54-10-image.png"></p>
<ul>
<li>使用 ATC 工具将 ONNX 模型转换为 OM 模型：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">atc --model=grid_sample_model.onnx --framework=5 --output=grid_sample_model --input_shape=<span class="string">&quot;input_x:1,1,64,64;input_grid:1,64,64,2&quot;</span> --soc_version=Ascend910B3</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-12-21-45-image.png"></p>
<hr>
<h5 id="5-开始推理验证"><a href="#5-开始推理验证" class="headerlink" title="5. 开始推理验证"></a>5. 开始推理验证</h5><ul>
<li>安装ais_bench推理工具：从<a target="_blank" rel="noopener" href="https://gitee.com/ascend/tools/tree/master/ais-bench_workload/tool/ais_bench">tools: Ascend tools - Gitee.com</a>，通过源代码编译安装</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> tools-master/ais-bench_workload/tool/ais_bench</span><br><span class="line">pip3 wheel ./backend/ -v</span><br><span class="line">pip3 wheel ./ -v</span><br><span class="line">pip3 install ./aclruntime-0.0.2-cp311-cp311-linux_aarch64.whl --force-reinstall</span><br><span class="line">pip3 install --force-reinstall <span class="string">&quot;numpy&lt;2.0&quot;</span></span><br><span class="line">pip3 install --no-deps ./ais_bench-0.0.2-py3-none-any.whl --force-reinstall</span><br><span class="line">pip3 install ./ais_bench-0.0.2-py3-none-any.whl --force-reinstall</span><br></pre></td></tr></table></figure>

<ul>
<li>生成输入数据<code>generate_bin.py</code></li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> prep_dataset</span><br><span class="line"><span class="built_in">cd</span> prep_dataset</span><br><span class="line">vim generate_bin.py</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    torch.manual_seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    N, C, H, W = <span class="number">1</span>, <span class="number">1</span>, <span class="number">64</span>, <span class="number">64</span></span><br><span class="line">    x = torch.randn(N, C, H, W, dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">    theta = torch.tensor([</span><br><span class="line">        [[<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],</span><br><span class="line">         [<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>]]</span><br><span class="line">    ], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">    grid = F.affine_grid(theta, size=(N, C, H, W), align_corners=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    x_np = x.cpu().numpy()</span><br><span class="line">    grid_np = grid.cpu().numpy()</span><br><span class="line"></span><br><span class="line">    x_np.tofile(<span class="string">&quot;input_x.bin&quot;</span>)</span><br><span class="line">    grid_np.tofile(<span class="string">&quot;input_grid.bin&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Generated two .bin files:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot; - input_x.bin    : shape <span class="subst">&#123;x_np.shape&#125;</span>, dtype <span class="subst">&#123;x_np.dtype&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot; - input_grid.bin : shape <span class="subst">&#123;grid_np.shape&#125;</span>, dtype <span class="subst">&#123;grid_np.dtype&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>运行脚本生成二进制输入文件，并创建相应目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python3 generate_bin.py</span><br><span class="line"><span class="built_in">mkdir</span> input_x_dir</span><br><span class="line"><span class="built_in">mkdir</span> input_grid_dir</span><br><span class="line"><span class="built_in">mv</span> input_x.bin input_x_dir/</span><br><span class="line"><span class="built_in">mv</span> input_grid.bin input_grid_dir/</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-13-40-43-image.png"></p>
<ul>
<li>使用 ais_bench 进行推理</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"><span class="built_in">source</span> /usr/local/Ascend/ascend-toolkit/set_env.sh</span><br><span class="line">python -m ais_bench --model grid_sample_model.om</span><br><span class="line"><span class="built_in">mkdir</span> output</span><br><span class="line">python3 -m ais_bench --model ./grid_sample_model.om --input ./prep_dataset/input_x_dir,./prep_dataset/input_grid_dir --output ./output/ --output_dirname result --outfmt TXT</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-13-32-18-image.png"></p>
<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-13-58-11-image.png"></p>
<hr>
<h5 id="6-更多性能数据"><a href="#6-更多性能数据" class="headerlink" title="6. 更多性能数据"></a>6. 更多性能数据</h5><p>创建或编辑 <code>acl.json</code> 文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim acl.json</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;profiler&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">              <span class="attr">&quot;switch&quot;</span><span class="punctuation">:</span> <span class="string">&quot;on&quot;</span><span class="punctuation">,</span></span><br><span class="line">              <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;./result/profiler&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>执行推理并采集性能数据：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m ais_bench --model ./grid_sample_model.om --acl_json_path ./acl.json</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-14-03-38-image.png"></p>
<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-14-03-57-image.png"></p>
<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-14-53-31-0fe95443ce374c44f2a10a4e775a91a.png"></p>
<hr>
<h5 id="7-算子支持与注意事项"><a href="#7-算子支持与注意事项" class="headerlink" title="7. 算子支持与注意事项"></a>7. 算子支持与注意事项</h5><ul>
<li>查看CANN算子规格</li>
</ul>
<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-21-01-15-31-image.png"></p>
<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-21-01-14-58-image.png"></p>
<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-20-16-11-image.png"></p>
<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-20-16-26-image.png"></p>
<p>如果使用GridSampler3D：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim export_grid_sample_3D.py</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GridSample3DModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(GridSample3DModel, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv3d = nn.Conv3d(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, </span><br><span class="line">                                kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, grid</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv3d(x)</span><br><span class="line">        out = F.grid_sample(</span><br><span class="line">            x, </span><br><span class="line">            grid, </span><br><span class="line">            mode=<span class="string">&#x27;bilinear&#x27;</span>,</span><br><span class="line">            padding_mode=<span class="string">&#x27;zeros&#x27;</span>,</span><br><span class="line">            align_corners=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    torch.manual_seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    model = GridSample3DModel().<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    N, C, D, H, W = <span class="number">1</span>, <span class="number">1</span>, <span class="number">8</span>, <span class="number">640</span>, <span class="number">640</span></span><br><span class="line">    x = torch.randn(N, C, D, H, W, dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">    theta = torch.tensor([[</span><br><span class="line">        [<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],</span><br><span class="line">        [<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>],</span><br><span class="line">        [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>],</span><br><span class="line">    ]], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">    grid = F.affine_grid(theta, size=(N, C, D, H, W), align_corners=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        out = model(x, grid)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;PyTorch output shape:&quot;</span>, out.shape)</span><br><span class="line"></span><br><span class="line">    onnx_model_path = <span class="string">&quot;grid_sample_3d_model.onnx&quot;</span></span><br><span class="line">    torch.onnx.export(</span><br><span class="line">        model,</span><br><span class="line">        (x, grid),</span><br><span class="line">        onnx_model_path,</span><br><span class="line">        export_params=<span class="literal">True</span>,</span><br><span class="line">        opset_version=<span class="number">16</span>,</span><br><span class="line">        do_constant_folding=<span class="literal">True</span>,</span><br><span class="line">        input_names=[<span class="string">&quot;input_x&quot;</span>, <span class="string">&quot;input_grid&quot;</span>],</span><br><span class="line">        output_names=[<span class="string">&quot;output&quot;</span>],</span><br><span class="line">        <span class="comment"># dynamic_axes=&#123;</span></span><br><span class="line">        <span class="comment">#   &quot;input_x&quot;: &#123;0: &quot;batch_size&quot;, 2: &quot;depth&quot;, 3: &quot;height&quot;, 4: &quot;width&quot;&#125;,</span></span><br><span class="line">        <span class="comment">#   &quot;input_grid&quot;: &#123;0: &quot;batch_size&quot;, 1: &quot;grid_depth&quot;, 2: &quot;grid_height&quot;, 3: &quot;grid_width&quot;&#125;,</span></span><br><span class="line">        <span class="comment">#   &quot;output&quot;: &#123;0: &quot;batch_size&quot;, 2: &quot;out_depth&quot;, 3: &quot;out_height&quot;, 4: &quot;out_width&quot;&#125;</span></span><br><span class="line">        <span class="comment"># &#125;</span></span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;ONNX model saved to: <span class="subst">&#123;onnx_model_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 export_grid_sample_3D.py</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-20-28-05-image.png"></p>
<ul>
<li><p>GridSampler2D 与 GridSampler3D 的限制</p>
<ul>
<li><p><strong>PyTorch ONNX 导出限制</strong>：目前 <code>torch.onnx.export</code> 仅支持 2D GridSample（4D 输入），不支持 3D（5D）输入，会报错。</p>
</li>
<li><p><strong>Ascend AI Core 支持</strong>：</p>
<ul>
<li>GridSampler3D 有 AI Core Kernel 实现，需 float32 前向；</li>
<li>GridSampler2D 目前仅支持在 AICPU 上执行，无法使用 AI Core。</li>
</ul>
</li>
</ul>
</li>
<li><p>3D grid_sample 的计算量通常远大于 2D，如果本来只是个 2D 任务，用 3D 人工加一维度可能并不能带来真正的功能收益，只是为了能够在 AI Core上执行。</p>
</li>
<li><p>这是一个前向支持 &#x2F; 后向不支持的状况。如果要在 Ascend AI Core 上做推理，又通过 ONNX&#x2F;OM 流程，目前<strong>没有官方开箱可行的方案</strong>。</p>
</li>
</ul>
<hr>
<h5 id="8-解决思路："><a href="#8-解决思路：" class="headerlink" title="8. 解决思路："></a>8. 解决思路：</h5><p>面对上述限制，以下是可能的应对思路：</p>
<ul>
<li><p><strong>使用 2D GridSample</strong>：如果不强制使用 AI Core 加速，可使用 2D GridSample，会在 AICPU 上运行，性能较低但流程简单。</p>
</li>
<li><p><strong>直接在 PyTorch + Ascend NPU 上推理</strong>：跳过 ONNX&#x2F;OM 转换，使用 <code>torch_npu</code> 在 Ascend NPU 上直接运行模型。</p>
</li>
<li><p><strong>使用 GridSampler3D</strong>：</p>
<ul>
<li><p>构造 5D 输入 <code>x</code>（形状 <code>[N, C, D, H, W]</code>，dtype float32）和 5D 网格 <code>grid</code>（形状 <code>[N, D, H, W, 3]</code>，dtype float32）。</p>
</li>
<li><p>在计算图中添加 GridSampler3D 节点，并设置相关属性。</p>
</li>
<li><p>使用 ATC 或其他编译器，将计算图编译为 <code>.om</code> 文件，在 AI Core 上执行。注意这种方式需要深入了解 Ascend 图编译流程。</p>
</li>
</ul>
</li>
<li><p><strong>自定义实现</strong>：自行实现 3D GridSample 的 ONNX symbolic 函数或 Ascend 自定义算子，但工作量较大。</p>
</li>
</ul>
<hr>
<h5 id="9-查询算子支持"><a href="#9-查询算子支持" class="headerlink" title="9. 查询算子支持"></a>9. 查询算子支持</h5><ul>
<li>使用 <code>ms_fast_query</code> 工具查询算子支持情况：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/Ascend/ascend-toolkit/latest/tools/ms_fast_query</span><br><span class="line">python3 ms_fast_query.py -t op --opp_path /usr/local/Ascend/ascend-toolkit/latest/opp -o /home/ljw/op.json</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-21-11-05-image.png"></p>
<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-20-21-11-20-image.png"></p>
<p>查询结果会生成在指定的 <code>op.json</code> 文件中，可用于查看算子支持详情。</p>
<hr>
<h5 id="10-查看算子原型"><a href="#10-查看算子原型" class="headerlink" title="10. 查看算子原型"></a>10. 查看算子原型</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/Ascend/ascend-toolkit/latest/opp/built-in/op_proto/</span><br><span class="line"><span class="built_in">cat</span> image_ops.h</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-21-01-04-19-image.png"></p>
<p><img src="/2025/01/22/9-GirdSample%E7%AE%97%E5%AD%90%E9%A2%84%E5%88%86%E6%9E%90/2025-01-21-01-06-12-image.png"></p>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/01/22/8-%E4%BD%BF%E7%94%A8CANN%E7%AE%97%E5%AD%90%E5%BA%93%E8%BF%9B%E8%A1%8C%E4%B8%A4%E6%AE%B5%E5%BC%8F%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="Jiawei Li">
      <meta itemprop="description" content="愚蠢的zzz侠">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="睿智的ljw侠">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/22/8-%E4%BD%BF%E7%94%A8CANN%E7%AE%97%E5%AD%90%E5%BA%93%E8%BF%9B%E8%A1%8C%E4%B8%A4%E6%AE%B5%E5%BC%8F%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/" class="post-title-link" itemprop="url">8-使用CANN算子库进行两段式接口调用</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-01-22 11:10:11" itemprop="dateCreated datePublished" datetime="2025-01-22T11:10:11+08:00">2025-01-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-01-23 11:51:37" itemprop="dateModified" datetime="2025-01-23T11:51:37+08:00">2025-01-23</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本教程指导如何使用 AscendCL 和 CANN 算子库接口 <code>aclnnGridSampler2D</code> 进行 2D 网格采样操作。</p>
<hr>
<h5 id="1-参考"><a href="#1-参考" class="headerlink" title="1. 参考"></a>1. 参考</h5><ul>
<li><p><a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/canncommercial/800/apiref/aolapi/context/aclnnGridSampler2D.md">aclnnGridSampler2D-NN算子接口-算子加速库-CANN商用版8.0.0开发文档-昇腾社区</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/canncommercial/800/developmentguide/appdevg/aclcppdevg/aclcppdevg_000019.html">调用NN&#x2F;融合算子接口示例代码-单算子API执行-单算子调用-AscendCL应用开发（C&amp;C++）-应用开发-CANN商用版8.0.0开发文档-昇腾社区</a></p>
</li>
</ul>
<hr>
<h5 id="2-示例代码"><a href="#2-示例代码" class="headerlink" title="2. 示例代码"></a>2. 示例代码</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim test_grid_sample2d.cpp</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;acl/acl.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;aclnnop/aclnn_grid_sampler2d.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CHECK_RET(cond, return_expr) \</span></span><br><span class="line"><span class="meta">  do &#123;                               \</span></span><br><span class="line"><span class="meta">    <span class="keyword">if</span> (!(cond)) &#123;                   \</span></span><br><span class="line"><span class="meta">      return_expr;                   \</span></span><br><span class="line"><span class="meta">    &#125;                                \</span></span><br><span class="line"><span class="meta">  &#125; while (0)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LOG_PRINT(message, ...)     \</span></span><br><span class="line"><span class="meta">  do &#123;                              \</span></span><br><span class="line"><span class="meta">    printf(message, ##__VA_ARGS__); \</span></span><br><span class="line"><span class="meta">  &#125; while (0)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int64_t</span> <span class="title">GetShapeSize</span><span class="params">(<span class="type">const</span> std::vector&lt;<span class="type">int64_t</span>&gt;&amp; shape)</span> </span>&#123;</span><br><span class="line">  <span class="type">int64_t</span> shapeSize = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> i : shape) &#123;</span><br><span class="line">    shapeSize *= i;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> shapeSize;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">Init</span><span class="params">(<span class="type">int32_t</span> deviceId, aclrtStream* stream)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 固定写法，AscendCL初始化</span></span><br><span class="line">  <span class="keyword">auto</span> ret = <span class="built_in">aclInit</span>(<span class="literal">nullptr</span>);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="built_in">LOG_PRINT</span>(<span class="string">&quot;aclInit failed. ERROR: %d\n&quot;</span>, ret); <span class="keyword">return</span> ret);</span><br><span class="line">  ret = <span class="built_in">aclrtSetDevice</span>(deviceId);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="built_in">LOG_PRINT</span>(<span class="string">&quot;aclrtSetDevice failed. ERROR: %d\n&quot;</span>, ret); <span class="keyword">return</span> ret);</span><br><span class="line">  ret = <span class="built_in">aclrtCreateStream</span>(stream);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="built_in">LOG_PRINT</span>(<span class="string">&quot;aclrtCreateStream failed. ERROR: %d\n&quot;</span>, ret); <span class="keyword">return</span> ret);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">CreateAclTensor</span><span class="params">(<span class="type">const</span> std::vector&lt;T&gt;&amp; hostData, <span class="type">const</span> std::vector&lt;<span class="type">int64_t</span>&gt;&amp; shape, <span class="type">void</span>** deviceAddr,</span></span></span><br><span class="line"><span class="params"><span class="function">                    aclDataType dataType, aclTensor** tensor)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> size = <span class="built_in">GetShapeSize</span>(shape) * <span class="built_in">sizeof</span>(T);</span><br><span class="line">  <span class="comment">// 调用aclrtMalloc申请device侧内存</span></span><br><span class="line">  <span class="keyword">auto</span> ret = <span class="built_in">aclrtMalloc</span>(deviceAddr, size, ACL_MEM_MALLOC_HUGE_FIRST);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="built_in">LOG_PRINT</span>(<span class="string">&quot;aclrtMalloc failed. ERROR: %d\n&quot;</span>, ret); <span class="keyword">return</span> ret);</span><br><span class="line">  <span class="comment">// 调用aclrtMemcpy将host侧数据复制到device侧内存上</span></span><br><span class="line">  ret = <span class="built_in">aclrtMemcpy</span>(*deviceAddr, size, hostData.<span class="built_in">data</span>(), size, ACL_MEMCPY_HOST_TO_DEVICE);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="built_in">LOG_PRINT</span>(<span class="string">&quot;aclrtMemcpy failed. ERROR: %d\n&quot;</span>, ret); <span class="keyword">return</span> ret);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 计算连续tensor的strides</span></span><br><span class="line">  <span class="function">std::vector&lt;<span class="type">int64_t</span>&gt; <span class="title">strides</span><span class="params">(shape.size(), <span class="number">1</span>)</span></span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int64_t</span> i = shape.<span class="built_in">size</span>() - <span class="number">2</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">    strides[i] = shape[i + <span class="number">1</span>] * strides[i + <span class="number">1</span>];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 调用aclCreateTensor接口创建aclTensor</span></span><br><span class="line">  *tensor = <span class="built_in">aclCreateTensor</span>(shape.<span class="built_in">data</span>(), shape.<span class="built_in">size</span>(), dataType, strides.<span class="built_in">data</span>(), <span class="number">0</span>, aclFormat::ACL_FORMAT_ND,</span><br><span class="line">                            shape.<span class="built_in">data</span>(), shape.<span class="built_in">size</span>(), *deviceAddr);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 1. （固定写法）device/stream初始化，参考AscendCL对外接口列表</span></span><br><span class="line">  <span class="comment">// 根据自己的实际device填写deviceId</span></span><br><span class="line">  <span class="type">int32_t</span> deviceId = <span class="number">0</span>;</span><br><span class="line">  aclrtStream stream;</span><br><span class="line">  <span class="keyword">auto</span> ret = <span class="built_in">Init</span>(deviceId, &amp;stream);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="built_in">LOG_PRINT</span>(<span class="string">&quot;Init acl failed. ERROR: %d\n&quot;</span>, ret); <span class="keyword">return</span> ret);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 2. 构造输入与输出，需要根据API的接口自定义构造</span></span><br><span class="line">  <span class="type">int64_t</span> interpolationMode = <span class="number">0</span>;</span><br><span class="line">  <span class="type">int64_t</span> paddingMode = <span class="number">0</span>;</span><br><span class="line">  <span class="type">bool</span> alignCorners = <span class="literal">false</span>;</span><br><span class="line">  std::vector&lt;<span class="type">int64_t</span>&gt; inputShape = &#123;<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">8</span>&#125;;</span><br><span class="line">  std::vector&lt;<span class="type">int64_t</span>&gt; gridShape = &#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>&#125;;</span><br><span class="line">  std::vector&lt;<span class="type">int64_t</span>&gt; outShape = &#123;<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>&#125;;</span><br><span class="line">  <span class="type">void</span>* inputDeviceAddr = <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="type">void</span>* gridDeviceAddr = <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="type">void</span>* outDeviceAddr = <span class="literal">nullptr</span>;</span><br><span class="line">  aclTensor* input = <span class="literal">nullptr</span>;</span><br><span class="line">  aclTensor* grid = <span class="literal">nullptr</span>;</span><br><span class="line">  aclTensor* out = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">  std::vector&lt;<span class="type">float</span>&gt; inputHostData = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>,</span><br><span class="line">                                      <span class="number">24</span>, <span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>, <span class="number">30</span>, <span class="number">31</span>, <span class="number">32</span>, <span class="number">33</span>, <span class="number">34</span>, <span class="number">35</span>, <span class="number">36</span>, <span class="number">37</span>, <span class="number">38</span>, <span class="number">39</span>, <span class="number">40</span>&#125;;</span><br><span class="line">  std::vector&lt;<span class="type">float</span>&gt; gridHostData = &#123;<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>&#125;;</span><br><span class="line">  std::vector&lt;<span class="type">float</span>&gt; outHostData = &#123;<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>&#125;;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 创建input aclTensor</span></span><br><span class="line">  ret = <span class="built_in">CreateAclTensor</span>(inputHostData, inputShape, &amp;inputDeviceAddr, aclDataType::ACL_FLOAT, &amp;input);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="keyword">return</span> ret);</span><br><span class="line">  <span class="comment">// 创建grid aclTensor</span></span><br><span class="line">  ret = <span class="built_in">CreateAclTensor</span>(gridHostData, gridShape, &amp;gridDeviceAddr, aclDataType::ACL_FLOAT, &amp;grid);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="keyword">return</span> ret);</span><br><span class="line">  <span class="comment">// 创建out aclTensor</span></span><br><span class="line">  ret = <span class="built_in">CreateAclTensor</span>(outHostData, outShape, &amp;outDeviceAddr, aclDataType::ACL_FLOAT, &amp;out);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="keyword">return</span> ret);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 3. 调用CANN算子库API，需要修改为具体的Api名称</span></span><br><span class="line">  <span class="type">uint64_t</span> workspaceSize = <span class="number">0</span>;</span><br><span class="line">  aclOpExecutor* executor;</span><br><span class="line">  <span class="comment">// 调用aclnnGridSampler2D第一段接口</span></span><br><span class="line">  ret = <span class="built_in">aclnnGridSampler2DGetWorkspaceSize</span>(input, grid, interpolationMode, paddingMode,alignCorners, out,</span><br><span class="line">                                           &amp;workspaceSize, &amp;executor);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="built_in">LOG_PRINT</span>(<span class="string">&quot;aclnnGridSampler2DGetWorkspaceSize failed. ERROR: %d\n&quot;</span>, ret); <span class="keyword">return</span> ret);</span><br><span class="line">  <span class="comment">// 根据第一段接口计算出的workspaceSize申请device内存</span></span><br><span class="line">  <span class="type">void</span>* workspaceAddr = <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="keyword">if</span> (workspaceSize &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    ret = <span class="built_in">aclrtMalloc</span>(&amp;workspaceAddr, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);</span><br><span class="line">    <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="built_in">LOG_PRINT</span>(<span class="string">&quot;allocate workspace failed. ERROR: %d\n&quot;</span>, ret); <span class="keyword">return</span> ret);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 调用aclnnGridSampler2D第二段接口</span></span><br><span class="line">  ret = <span class="built_in">aclnnGridSampler2D</span>(workspaceAddr, workspaceSize, executor, stream);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="built_in">LOG_PRINT</span>(<span class="string">&quot;aclnnGridSampler2D failed. ERROR: %d\n&quot;</span>, ret); <span class="keyword">return</span> ret);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 4. （固定写法）同步等待任务执行结束</span></span><br><span class="line">  ret = <span class="built_in">aclrtSynchronizeStream</span>(stream);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="built_in">LOG_PRINT</span>(<span class="string">&quot;aclrtSynchronizeStream failed. ERROR: %d\n&quot;</span>, ret); <span class="keyword">return</span> ret);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 5. 获取输出的值，将device侧内存上的结果复制至host侧，需要根据具体API的接口定义修改</span></span><br><span class="line">  <span class="keyword">auto</span> size = <span class="built_in">GetShapeSize</span>(outShape);</span><br><span class="line">  <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">resultData</span><span class="params">(size, <span class="number">0</span>)</span></span>;</span><br><span class="line">  ret = <span class="built_in">aclrtMemcpy</span>(resultData.<span class="built_in">data</span>(), resultData.<span class="built_in">size</span>() * <span class="built_in">sizeof</span>(resultData[<span class="number">0</span>]),</span><br><span class="line">                    outDeviceAddr, size * <span class="built_in">sizeof</span>(resultData[<span class="number">0</span>]), ACL_MEMCPY_DEVICE_TO_HOST);</span><br><span class="line">  <span class="built_in">CHECK_RET</span>(ret == ACL_SUCCESS, <span class="built_in">LOG_PRINT</span>(<span class="string">&quot;copy resultData from device to host failed. ERROR: %d\n&quot;</span>, ret);</span><br><span class="line">            <span class="keyword">return</span> ret);</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int64_t</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">    <span class="built_in">LOG_PRINT</span>(<span class="string">&quot;resultData[%ld] is: %f\n&quot;</span>, i, resultData[i]);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 6. 释放aclTensor，需要根据具体API的接口定义修改</span></span><br><span class="line">  <span class="built_in">aclDestroyTensor</span>(input);</span><br><span class="line">  <span class="built_in">aclDestroyTensor</span>(grid);</span><br><span class="line">  <span class="built_in">aclDestroyTensor</span>(out);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 7. 释放Device资源，需要根据具体API的接口定义修改</span></span><br><span class="line">  <span class="built_in">aclrtFree</span>(inputDeviceAddr);</span><br><span class="line">  <span class="built_in">aclrtFree</span>(gridDeviceAddr);</span><br><span class="line">  <span class="built_in">aclrtFree</span>(outDeviceAddr);</span><br><span class="line">  <span class="keyword">if</span> (workspaceSize &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="built_in">aclrtFree</span>(workspaceAddr);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">aclrtDestroyStream</span>(stream);</span><br><span class="line">  <span class="built_in">aclrtResetDevice</span>(deviceId);</span><br><span class="line">  <span class="built_in">aclFinalize</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<hr>
<h5 id="3-CMakeLists配置"><a href="#3-CMakeLists配置" class="headerlink" title="3. CMakeLists配置"></a>3. CMakeLists配置</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim CMakeLists.txt</span><br></pre></td></tr></table></figure>

<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CMake lowest version requirement</span></span><br><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.14</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置工程名</span></span><br><span class="line"><span class="keyword">project</span>(ACLNN_EXAMPLE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compile options</span></span><br><span class="line"><span class="keyword">add_compile_options</span>(-std=c++<span class="number">11</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置编译选项</span></span><br><span class="line"><span class="keyword">set</span>(CMAKE_RUNTIME_OUTPUT_DIRECTORY  <span class="string">&quot;./bin&quot;</span>)    </span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_FLAGS_DEBUG <span class="string">&quot;-fPIC -O0 -g -Wall&quot;</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_FLAGS_RELEASE <span class="string">&quot;-fPIC -O2 -Wall&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置可执行文件名（如opapi_test），并指定待运行算子文件*.cpp所在目录</span></span><br><span class="line"><span class="keyword">add_executable</span>(opapi_test</span><br><span class="line">               test_grid_sample2d.cpp) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置ASCEND_PATH（CANN软件包目录，请根据实际路径修改）和INCLUDE_BASE_DIR（头文件目录）</span></span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">NOT</span> <span class="string">&quot;$ENV&#123;ASCEND_CUSTOM_PATH&#125;&quot;</span> <span class="keyword">STREQUAL</span> <span class="string">&quot;&quot;</span>)      </span><br><span class="line">    <span class="keyword">set</span>(ASCEND_PATH $ENV&#123;ASCEND_CUSTOM_PATH&#125;)</span><br><span class="line"><span class="keyword">else</span>()</span><br><span class="line">    <span class="keyword">set</span>(ASCEND_PATH <span class="string">&quot;/usr/local/Ascend/ascend-toolkit/latest&quot;</span>)</span><br><span class="line"><span class="keyword">endif</span>()</span><br><span class="line"><span class="keyword">set</span>(INCLUDE_BASE_DIR <span class="string">&quot;$&#123;ASCEND_PATH&#125;/include&quot;</span>)</span><br><span class="line"><span class="keyword">include_directories</span>(</span><br><span class="line">    <span class="variable">$&#123;INCLUDE_BASE_DIR&#125;</span></span><br><span class="line">    <span class="variable">$&#123;INCLUDE_BASE_DIR&#125;</span>/aclnn</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置链接的库文件路径</span></span><br><span class="line"><span class="keyword">target_link_libraries</span>(opapi_test PRIVATE</span><br><span class="line">                      <span class="variable">$&#123;ASCEND_PATH&#125;</span>/lib64/libascendcl.so</span><br><span class="line">                      <span class="variable">$&#123;ASCEND_PATH&#125;</span>/lib64/libnnopbase.so</span><br><span class="line">                      <span class="variable">$&#123;ASCEND_PATH&#125;</span>/lib64/libopapi.so)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可执行文件在CMakeLists文件所在目录的bin目录下</span></span><br><span class="line"><span class="keyword">install</span>(TARGETS opapi_test DESTINATION <span class="variable">$&#123;CMAKE_RUNTIME_OUTPUT_DIRECTORY&#125;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h5 id="4-编译与运行"><a href="#4-编译与运行" class="headerlink" title="4. 编译与运行"></a>4. 编译与运行</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apt-get update</span><br><span class="line">apt-get install -y cmake</span><br><span class="line"><span class="built_in">source</span> /usr/local/Ascend/ascend-toolkit/set_env.sh</span><br><span class="line"><span class="built_in">mkdir</span> -p build </span><br><span class="line"><span class="built_in">cd</span> build</span><br><span class="line">cmake ../ -DCMAKE_CXX_COMPILER=g++ -DCMAKE_SKIP_RPATH=TRUE</span><br><span class="line">make</span><br><span class="line"><span class="built_in">cd</span> bin</span><br><span class="line">./opapi_test</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/22/8-%E4%BD%BF%E7%94%A8CANN%E7%AE%97%E5%AD%90%E5%BA%93%E8%BF%9B%E8%A1%8C%E4%B8%A4%E6%AE%B5%E5%BC%8F%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/2025-01-22-09-59-42-image.png"></p>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="Jiawei Li">
      <meta itemprop="description" content="愚蠢的zzz侠">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="睿智的ljw侠">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/" class="post-title-link" itemprop="url">7-ResNet50模型在华为昇腾平台上的训练与部署</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-01-21 15:10:11" itemprop="dateCreated datePublished" datetime="2025-01-21T15:10:11+08:00">2025-01-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-01-22 13:40:02" itemprop="dateModified" datetime="2025-01-22T13:40:02+08:00">2025-01-22</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本文档详细介绍了如何在华为昇腾（Ascend）平台上迁移、训练和部署ResNet50模型。包括从数据准备、修改训练脚本、下载数据集、模型训练、导出ONNX模型、转换为OM模型，到最终的模型推理。</p>
<hr>
<h5 id="1-参考"><a href="#1-参考" class="headerlink" title="1. 参考"></a>1. 参考</h5><ul>
<li><p><a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/800alpha003/quickstart/quickstart/quickstart_18_0008.html">模型迁移与训练-快速入门-从这里开始-CANN社区版8.0.0.alpha003开发文档-昇腾社区</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/pytorch/examples/blob/f5bb60f8e6b2881be3a2ea8c9a3d43e676aa2340/imagenet/main.py">examples&#x2F;imagenet&#x2F;main.py at f5bb60f8e6b2881be3a2ea8c9a3d43e676aa2340 · pytorch&#x2F;examples · GitHub</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://image-net.org/download-images.php">ImageNet</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/42696535">https://zhuanlan.zhihu.com/p/42696535</a></p>
</li>
</ul>
<hr>
<h5 id="2-修改训练脚本"><a href="#2-修改训练脚本" class="headerlink" title="2. 修改训练脚本"></a>2. 修改训练脚本</h5><p><strong>背景</strong></p>
<ul>
<li>当前昇腾适配的PyTorch版本不支持 <code>torch.backends.mps</code> 模块，该模块主要用于支持Apple的Metal Performance Shaders (MPS) 后端。昇腾平台主要使用华为自研的AI计算架构，因此无需使用 <code>torch.backends.mps</code>。</li>
</ul>
<p><strong>修改步骤</strong></p>
<ul>
<li>在训练脚本中查找并删除所有涉及 <code>torch.backends.mps</code> 的代码。(5处)</li>
</ul>
<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-12-01-00-07-image.png"></p>
<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-12-01-00-43-image.png"></p>
<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-12-01-01-03-image.png"></p>
<ul>
<li>导入昇腾相关库</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch_npu</span><br><span class="line"><span class="keyword">from</span> torch_npu.contrib <span class="keyword">import</span> transfer_to_npu</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-15-12-57-28-image.png"></p>
<hr>
<h5 id="3-下载ImageNet数据集数据集"><a href="#3-下载ImageNet数据集数据集" class="headerlink" title="3. 下载ImageNet数据集数据集"></a>3. 下载ImageNet数据集数据集</h5><p>下载 <a target="_blank" rel="noopener" href="https://www.image-net.org/">https://www.image-net.org/</a> 三个文件：</p>
<ul>
<li>训练图像（Task 1 &amp; 2） Training images (Task 1 &amp; 2). 138GB.</li>
<li>验证图像（所有任务） Validation images (all tasks). 6.3GB.</li>
<li>训练边界框注释（仅Task 1 &amp; 2）Training bounding box annotations (Task 1 &amp; 2 only). 20MB.</li>
</ul>
<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-12-15-48-25-image.png"></p>
<p>解压与整理</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">imagenet</span><br><span class="line">├── train</span><br><span class="line">│   ├── n01440764</span><br><span class="line">│   ├── n01443537</span><br><span class="line">│   ├── ...</span><br><span class="line">└── <span class="keyword">val</span></span><br><span class="line">    ├── n01440764</span><br><span class="line">    ├── n01443537</span><br><span class="line">    ├── ...</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p imagenet/train</span><br><span class="line">tar -xvf ILSVRC2012_img_train.tar -C imagenet/train</span><br><span class="line"><span class="built_in">cd</span> imagenet/train</span><br><span class="line">find . -name <span class="string">&quot;*.tar&quot;</span> | <span class="keyword">while</span> <span class="built_in">read</span> NAME ; <span class="keyword">do</span> <span class="built_in">mkdir</span> -p <span class="string">&quot;<span class="variable">$&#123;NAME%.tar&#125;</span>&quot;</span>; tar -xvf <span class="string">&quot;<span class="variable">$&#123;NAME&#125;</span>&quot;</span> -C <span class="string">&quot;<span class="variable">$&#123;NAME%.tar&#125;</span>&quot;</span>; <span class="built_in">rm</span> -f <span class="string">&quot;<span class="variable">$&#123;NAME&#125;</span>&quot;</span>; <span class="keyword">done</span></span><br><span class="line"><span class="built_in">cd</span> ../..</span><br><span class="line"><span class="built_in">mkdir</span> imagenet/val</span><br><span class="line">tar -xvf ILSVRC2012_img_val.tar -C imagenet/val</span><br><span class="line"><span class="built_in">cd</span> imagenet/val</span><br><span class="line">wget -qO- https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh | bash</span><br></pre></td></tr></table></figure>

<p>验证数据完整性</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find train/ -name <span class="string">&quot;*.JPEG&quot;</span> | <span class="built_in">wc</span> -l  <span class="comment"># 1281167</span></span><br><span class="line">find val/ -name <span class="string">&quot;*.JPEG&quot;</span> | <span class="built_in">wc</span> -l    <span class="comment"># 50000</span></span><br></pre></td></tr></table></figure>

<hr>
<h5 id="4-训练"><a href="#4-训练" class="headerlink" title="4. 训练"></a>4. 训练</h5><p>配置环境变量</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /usr/local/Ascend/ascend-toolkit/set_env.sh</span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=/usr/local/Ascend/ascend-toolkit/latest/tools/ms_fmk_transplt/torch_npu_bridge:<span class="variable">$PYTHONPATH</span></span><br></pre></td></tr></table></figure>

<p>安装必要依赖</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt-get update</span><br><span class="line">apt-get install -y screen build-essential cmake</span><br></pre></td></tr></table></figure>

<p>启动screen会话，执行单卡训练</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/ljw/data</span><br><span class="line">screen -S resnet</span><br><span class="line">python3 main.py /home/ljw/data/resnet50/imagenet --batch-size 64 --lr 0.025 --epochs 1 --<span class="built_in">arch</span> resnet50 --world-size 1 --rank 0 --workers 40 --momentum 0.9 --weight-decay 1e-4 --gpu 0</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-15-14-09-04-image.png"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ll</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-15-15-24-39-image.png"></p>
<p>按下 <code>Ctrl+A</code>分离screen会话，然后按 <code>D</code> 键将会话分离。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">screen -<span class="built_in">ls</span>    <span class="comment"># 列出所有 screen 会话</span></span><br><span class="line">screen -r  <span class="comment"># 恢复（attach）到一个会话</span></span><br><span class="line"><span class="comment"># screen -r -D 105654.resnet</span></span><br><span class="line"><span class="comment"># ps aux | grep python</span></span><br><span class="line"><span class="comment"># kill -9 PID</span></span><br><span class="line">screen -S 71313.resnet -X quit  <span class="comment"># 删除会话</span></span><br></pre></td></tr></table></figure>

<p>继续训练</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 main.py /home/ljw/data/resnet50/imagenet --batch-size 64 --lr 0.025 --epochs 10 --<span class="built_in">arch</span> resnet50 --world-size 1 --rank 0 --workers 40 --momentum 0.9 --weight-decay 1e-4 --gpu 0 --resume checkpoint.pth.tar</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-15-15-27-52-image.png"></p>
<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-16-16-35-03-image.png"></p>
<p>其中：</p>
<ul>
<li>损失值：起始大约在 6～7，随训练逐渐下降，达到1～2左右时表明模型已经学习了不少特征。</li>
<li>Top-1 准确率：初期可能低于 1%，成熟模型可能在 75%～77% 左右（对于 ResNet-50 训练 ImageNet）。</li>
<li>Top-5 准确率：初期同样很低，训练后期可能超过 90%，通常在 92%～93% 范围内。</li>
<li>传统 ImageNet Baseline 通常训练 90 个 Epoch（ResNet 系列经典做法）或更多。</li>
</ul>
<hr>
<h5 id="5-导出ONNX模型"><a href="#5-导出ONNX模型" class="headerlink" title="5. 导出ONNX模型"></a>5. 导出ONNX模型</h5><p>安装ONNX</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip3 install onnx</span><br><span class="line">vim pth2onnx.py</span><br></pre></td></tr></table></figure>

<p>编写转换脚本 <code>pth2onnx.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch_npu</span><br><span class="line"><span class="keyword">import</span> torch.onnx</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">proc_nodes_module</span>(<span class="params">checkpoint, AttrName</span>):</span><br><span class="line">    new_state_dict = OrderedDict()</span><br><span class="line">    <span class="keyword">for</span> key, value <span class="keyword">in</span> checkpoint[AttrName].items():</span><br><span class="line">        <span class="keyword">if</span> key == <span class="string">&quot;module.features.0.0.weight&quot;</span>:</span><br><span class="line">            <span class="built_in">print</span>(value)</span><br><span class="line">        <span class="comment"># 根据实际前缀后缀情况修改</span></span><br><span class="line">        <span class="keyword">if</span>(key[<span class="number">0</span>:<span class="number">7</span>] == <span class="string">&quot;module.&quot;</span>):</span><br><span class="line">            name = key[<span class="number">7</span>:]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            name = key[<span class="number">0</span>:]</span><br><span class="line"></span><br><span class="line">        new_state_dict[name] = value</span><br><span class="line">    <span class="keyword">return</span> new_state_dict</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert</span>():</span><br><span class="line">    <span class="comment"># 模型定义来自于torchvision，样例生成的模型文件是基于resnet50模型</span></span><br><span class="line">    checkpoint = torch.load(<span class="string">&quot;./checkpoint.pth.tar&quot;</span>, map_location=torch.device(<span class="string">&#x27;cpu&#x27;</span>))    <span class="comment"># 根据实际文件名称修改</span></span><br><span class="line">    checkpoint[<span class="string">&#x27;state_dict&#x27;</span>] = proc_nodes_module(checkpoint,<span class="string">&#x27;state_dict&#x27;</span>)</span><br><span class="line">    model = models.resnet50(pretrained = <span class="literal">False</span>)</span><br><span class="line">    model.load_state_dict(checkpoint[<span class="string">&#x27;state_dict&#x27;</span>])</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    input_names = [<span class="string">&quot;actual_input_1&quot;</span>]</span><br><span class="line">    output_names = [<span class="string">&quot;output1&quot;</span>]</span><br><span class="line">    dummy_input = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">    torch.onnx.export(model, dummy_input, <span class="string">&quot;resnet50.onnx&quot;</span>, input_names = input_names, output_names = output_names, opset_version=<span class="number">11</span>)    <span class="comment"># 输出文件名根据实际情况修改</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    convert()</span><br></pre></td></tr></table></figure>

<p>执行转换</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 pth2onnx.py</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-21-16-40-21-image.png"></p>
<hr>
<h5 id="6-将ONNX模型转换为OM模型"><a href="#6-将ONNX模型转换为OM模型" class="headerlink" title="6. 将ONNX模型转换为OM模型"></a>6. 将ONNX模型转换为OM模型</h5><p>使用ATC工具</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">atc --model=resnet50.onnx --framework=5 --output=resnet50 --input_shape=<span class="string">&quot;actual_input_1:1,3,224,224&quot;</span>  --soc_version=Ascend910B3</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-21-16-42-43-image.png"></p>
<hr>
<h5 id="7-模型加载与推理"><a href="#7-模型加载与推理" class="headerlink" title="7. 模型加载与推理"></a>7. 模型加载与推理</h5><ul>
<li><p>代码：<a target="_blank" rel="noopener" href="https://gitee.com/ascend/samples/tree/master/cplusplus/level2_simple_inference/1_classification/resnet50_firstapp">samples: CANN Samples - Gitee.com</a></p>
</li>
<li><p>将om模型存放到resnet50_firstapp&#x2F;mode目录下</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> resnet50.om resnet50_firstapp/model/</span><br><span class="line"><span class="built_in">cd</span> resnet50_firstapp/data/</span><br><span class="line">wget https://obs-9be7.obs.cn-east-2.myhuaweicloud.com/models/aclsample/dog1_1024_683.jpg --no-check-certificate</span><br></pre></td></tr></table></figure>

<p>编译推理代码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> APP_SOURCE_PATH=/home/ljw/data/resnet50_firstapp</span><br><span class="line"><span class="built_in">export</span> DDK_PATH=/usr/local/Ascend/ascend-toolkit/latest</span><br><span class="line"><span class="built_in">export</span> NPU_HOST_LIB=/usr/local/Ascend/ascend-toolkit/latest/aarch64-linux/devlib</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install -y cmake</span><br><span class="line"><span class="built_in">chmod</span> +x sample_build.sh</span><br><span class="line">./sample_build.sh</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-21-17-08-37-image.png"></p>
<p>运行推理应用</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x sample_run.sh</span><br><span class="line">./sample_run.sh</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/21/7-ResNet50%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%98%87%E8%85%BE%E5%B9%B3%E5%8F%B0%E4%B8%8A%E7%9A%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E9%83%A8%E7%BD%B2/2025-01-21-17-09-43-image.png"></p>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="Jiawei Li">
      <meta itemprop="description" content="愚蠢的zzz侠">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="睿智的ljw侠">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/" class="post-title-link" itemprop="url">6-基于I2C接口传感器的用户态6轴IMU姿态解算程序</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-01-14 15:10:11 / 修改时间：17:48:36" itemprop="dateCreated datePublished" datetime="2025-01-14T15:10:11+08:00">2025-01-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h5 id="1-参考"><a href="#1-参考" class="headerlink" title="1. 参考"></a>1. 参考</h5><ul>
<li><p><a target="_blank" rel="noopener" href="https://gitee.com/ascend/ascend_community_projects/tree/310B/A200IDKA2MPU6050PostureVisualization">https://gitee.com/ascend/ascend_community_projects/tree/310B/A200IDKA2MPU6050PostureVisualization</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/Atlas200IDKA2DeveloperKit/23.0.RC2/Hardware%20Interfaces/hiug/hiug_0006.html">使用串口登录-远程登录-硬件接口使用指南-硬件使用-Atlas 200I DK A2开发者套件23.0.RC3开发文档-昇腾社区</a></p>
</li>
</ul>
<hr>
<h5 id="2-环境准备"><a href="#2-环境准备" class="headerlink" title="2. 环境准备"></a>2. 环境准备</h5><p>硬件设备</p>
<ul>
<li>昇腾 Atlas 200I DK A2 开发者套件</li>
<li>MPU6050 传感器模块</li>
<li>USB 转串口模块</li>
<li>Windows&#x2F;Linux PC（需安装对应 USB 转串口驱动）</li>
</ul>
<p>软件环境</p>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-16-01-38-image.png"></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://gitee.com/ascend/ascend_community_projects/tree/310B/A200IDKA2MPU6050PostureVisualization">https://gitee.com/ascend/ascend_community_projects/tree/310B/A200IDKA2MPU6050PostureVisualization</a></li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install pyserial</span><br><span class="line">conda install -c conda-forge smbus2</span><br></pre></td></tr></table></figure>

<hr>
<h5 id="3-串口连接"><a href="#3-串口连接" class="headerlink" title="3. 串口连接"></a>3. 串口连接</h5><ul>
<li>USB 转串口模块连接 A2 套件</li>
</ul>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-15-45-06-image.png"></p>
<p>usb转串口CH340T</p>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-15-52-39-image.png"></p>
<p>将 USB 转串口线的一端与 A2 套件的串口接口连接</p>
<ul>
<li>TX 对 RX</li>
<li>RX 对 TX</li>
<li>GND 对 GND</li>
</ul>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-15-53-12-image.png"></p>
<p>另一端连接电脑 USB 接口</p>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-15-53-40-image.png"></p>
<p>PC 上安装好 USB 转串口驱动后，可在“设备管理器”或相应工具中查看到新的端口（如 Windows 上显示 “COM7” 等）</p>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-15-54-39-image.png"></p>
<p>可通过Xshell等连接串口</p>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-16-05-48-image.png"></p>
<hr>
<h5 id="4-MPU6050传感器连接"><a href="#4-MPU6050传感器连接" class="headerlink" title="4. MPU6050传感器连接"></a>4. MPU6050传感器连接</h5><p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-16-54-29-image.png"></p>
<p>根据表格，对应连接</p>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-16-54-52-image.png"></p>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-16-55-16-image.png"></p>
<hr>
<h5 id="5-运行示例"><a href="#5-运行示例" class="headerlink" title="5. 运行示例"></a>5. 运行示例</h5><p>下载 <a target="_blank" rel="noopener" href="https://processing.org/download">https://processing.org/download</a> 用以打开motion_display.pde文件</p>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-16-38-30-image.png"></p>
<p>将原代码中COM3改成自己端口对应名称（如COM7），未连接传感器时点击运行可看到一个长方体</p>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-16-39-55-image.png"></p>
<p>执行代码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python mpu6050_motion.py</span><br></pre></td></tr></table></figure>

<p>可看到打印输出姿态信息，以及模拟可视化状态</p>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-16-57-12-image.png"></p>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/2025-01-14-16-57-50-image.png"></p>
<p><img src="/2025/01/14/6-%E5%9F%BA%E4%BA%8EI2C%E6%8E%A5%E5%8F%A3%E4%BC%A0%E6%84%9F%E5%99%A8%E7%9A%84%E7%94%A8%E6%88%B7%E6%80%816%E8%BD%B4IMU%E5%A7%BF%E6%80%81%E8%A7%A3%E7%AE%97%E7%A8%8B%E5%BA%8F/b4444eff814003cd77e9cf72a067354f.gif"></p>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/01/08/5-%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="Jiawei Li">
      <meta itemprop="description" content="愚蠢的zzz侠">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="睿智的ljw侠">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/08/5-%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA/" class="post-title-link" itemprop="url">5-实现微信机器人</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-01-08 14:44:40 / 修改时间：14:35:44" itemprop="dateCreated datePublished" datetime="2025-01-08T14:44:40+08:00">2025-01-08</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>使用开源代码在服务器上部署微信小机器人。该机器人基于大模型构建，支持微信公众号、企业微信、飞书、钉钉等多平台接入，并且可以处理文本、语音和图片等多种输入。</p>
<hr>
<h5 id="1-参考资料"><a href="#1-参考资料" class="headerlink" title="1. 参考资料"></a>1. 参考资料</h5><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/zhayujie/chatgpt-on-wechat">GitHub - zhayujie&#x2F;chatgpt-on-wechat: 基于大模型搭建的聊天机器人，同时支持 微信公众号、企业微信应用、飞书、钉钉 等接入，可选择GPT3.5&#x2F;GPT-4o&#x2F;GPT-o1&#x2F; Claude&#x2F;文心一言&#x2F;讯飞星火&#x2F;通义千问&#x2F; Gemini&#x2F;GLM-4&#x2F;Claude&#x2F;Kimi&#x2F;LinkAI，能处理文本、语音和图片，访问操作系统和互联网，支持基于自有知识库进行定制企业智能客服。</a></li>
</ul>
<hr>
<h5 id="2-运行环境"><a href="#2-运行环境" class="headerlink" title="2. 运行环境"></a>2. 运行环境</h5><p>需准备服务器、OpenAI接口的API Key。按照该项目ReadMe准备环境：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/zhayujie/chatgpt-on-wechat</span><br><span class="line"><span class="built_in">cd</span> chatgpt-on-wechat</span><br><span class="line">pip3 install -r requirements.txt/</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/08/5-%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA/2025-01-08-14-03-04-image.png"></p>
<hr>
<h5 id="3-配置"><a href="#3-配置" class="headerlink" title="3. 配置"></a>3. 配置</h5><p><img src="/2025/01/08/5-%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA/2025-01-08-14-07-13-image.png"></p>
<p>将open_ai_api_key、open_ai_api_base改成自己的API Key。示例：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;model&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt-4o&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;open_ai_api_key&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ZZZXXX7dAYOURKEY&quot;</span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">&quot;open_ai_api_base&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://api.openai.com/v1&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;single_chat_prefix&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;single_chat_reply_prefix&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[来自泽泽的回复] &quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;group_chat_prefix&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;@泽泽&quot;</span><span class="punctuation">,</span> <span class="string">&quot;泽泽&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">&quot;group_name_white_list&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;泽泽&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">&quot;group_chat_in_one_session&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;泽泽&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;image_create_prefix&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;看&quot;</span><span class="punctuation">,</span> <span class="string">&quot;画&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span>  </span><br><span class="line">  <span class="attr">&quot;speech_recognition&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">&quot;group_speech_recognition&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">&quot;voice_reply_voice&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">&quot;character_desc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你的名字是泽泽，是一只毛茸茸的可爱狗狗，你可以用各国语言交流，正常用中文对话&quot;</span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">&quot;use_linkai&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">&quot;linkai_api_key&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;linkai_app_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span> </span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/08/5-%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA/2025-01-08-14-08-29-image.png"></p>
<hr>
<h5 id="4-运行"><a href="#4-运行" class="headerlink" title="4. 运行"></a>4. 运行</h5><p><img src="/2025/01/08/5-%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA/2025-01-08-14-12-59-image.png"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">nohup</span> python3 app.py &amp; <span class="built_in">tail</span> -f nohup.out</span><br><span class="line"><span class="comment"># ps -ef | grep app.py | grep -v grep # 查看进程</span></span><br><span class="line"><span class="comment"># 重新启动 kill 进程</span></span><br><span class="line"><span class="comment"># tail -f nohup.out # 打开日志</span></span><br></pre></td></tr></table></figure>

<hr>
<h5 id="5-查看效果"><a href="#5-查看效果" class="headerlink" title="5. 查看效果"></a>5. 查看效果</h5><ul>
<li>群聊效果：</li>
</ul>
<p><img src="/2025/01/08/5-%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA/2025-01-08-14-16-02-image.png"></p>
<ul>
<li>私聊效果</li>
</ul>
<p><img src="/2025/01/08/5-%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA/2025-01-08-14-19-06-image.png"></p>
<p><img src="/2025/01/08/5-%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E6%9C%BA%E5%99%A8%E4%BA%BA/2025-01-08-14-19-47-image.png"></p>
<p>嘿嘿！</p>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/01/06/4-%E4%B8%8B%E8%BD%BD%E5%B9%B6%E4%BD%BF%E7%94%A8MindIE%E6%B5%8B%E8%AF%95GLM-4-9B-Chat%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.jpg">
      <meta itemprop="name" content="Jiawei Li">
      <meta itemprop="description" content="愚蠢的zzz侠">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="睿智的ljw侠">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/01/06/4-%E4%B8%8B%E8%BD%BD%E5%B9%B6%E4%BD%BF%E7%94%A8MindIE%E6%B5%8B%E8%AF%95GLM-4-9B-Chat%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">4-下载并使用MindIE测试GLM-4-9B-Chat模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-01-06 14:44:40" itemprop="dateCreated datePublished" datetime="2025-01-06T14:44:40+08:00">2025-01-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-01-08 13:53:23" itemprop="dateModified" datetime="2025-01-08T13:53:23+08:00">2025-01-08</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本教程介绍如何快速从 Hugging Face 下载 GLM-4-9B-Chat 模型的权重文件，并在 Ascend 平台上进行模型推理和性能测试。</p>
<hr>
<h5 id="1-参考资料"><a href="#1-参考资料" class="headerlink" title="1. 参考资料"></a>1. 参考资料</h5><ul>
<li><p><a target="_blank" rel="noopener" href="https://padeoe.com/huggingface-large-models-downloader/">如何快速下载huggingface大模型 &#8211; padeoe的小站</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/mindie/10RC3/whatismindie/mindie_what_0011.html">模型推理测试-模型开箱-MindIE是什么-MindIE1.0.RC3开发文档-昇腾社区</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.hiascend.com/document/detail/zh/mindie/10RC3/whatismindie/mindie_what_0012.html">模型性能测试-模型开箱-MindIE是什么-MindIE1.0.RC3开发文档-昇腾社区</a></p>
</li>
</ul>
<hr>
<h5 id="2-从Hugging-Face下载权重文件"><a href="#2-从Hugging-Face下载权重文件" class="headerlink" title="2. 从Hugging Face下载权重文件"></a>2. 从Hugging Face下载权重文件</h5><p>安装 Hugging Face Hub，并设置环境变量以禁用 HF 传输加速。可以选择使用 <code>huggingface-cli</code> 或编写 Python 脚本来下载模型。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install -U huggingface_hub</span><br><span class="line"><span class="built_in">export</span> HF_HUB_ENABLE_HF_TRANSFER=<span class="literal">false</span></span><br><span class="line"><span class="comment"># huggingface-cli download --resume-download THUDM/glm-4-9b-chat --local-dir glm-4-9b-chat</span></span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/06/4-%E4%B8%8B%E8%BD%BD%E5%B9%B6%E4%BD%BF%E7%94%A8MindIE%E6%B5%8B%E8%AF%95GLM-4-9B-Chat%E6%A8%A1%E5%9E%8B/2025-01-06-10-41-25-d8c892e387bb942c6a4a863d3aa5bc8.png"></p>
<p>使用 Python 脚本，创建<code>download_model.py</code> ，下载指定模型名称和 commit ID。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># download_model.py</span></span><br><span class="line"><span class="keyword">from</span> huggingface_hub <span class="keyword">import</span> snapshot_download</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;THUDM/glm-4-9b-chat&quot;</span></span><br><span class="line">commit_id = <span class="string">&quot;e824789b14985787c181beaac940d103b2516cb0&quot;</span></span><br><span class="line"></span><br><span class="line">snapshot_download(repo_id=model_name, revision=commit_id, local_dir=<span class="string">&quot;glm-4-9b-chat&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>运行脚本以开始下载：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 download_model.py</span><br></pre></td></tr></table></figure>

<hr>
<h5 id="3-模型推理测试"><a href="#3-模型推理测试" class="headerlink" title="3. 模型推理测试"></a>3. 模型推理测试</h5><p>下载完成后，在 Ascend 平台上进行模型推理测试。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/Ascend/llm_model</span><br><span class="line">bash examples/models/chatglm/v2_6b/run_800i_a2_pa.sh /home/ljw/glm-4-9b-chat</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/06/4-%E4%B8%8B%E8%BD%BD%E5%B9%B6%E4%BD%BF%E7%94%A8MindIE%E6%B5%8B%E8%AF%95GLM-4-9B-Chat%E6%A8%A1%E5%9E%8B/2025-01-06-10-39-19-image.png"></p>
<hr>
<h5 id="4-模型性能测试"><a href="#4-模型性能测试" class="headerlink" title="4. 模型性能测试"></a>4. 模型性能测试</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/Ascend/llm_model/tests/modeltest</span><br><span class="line">bash run.sh pa_bf16 performance [[2048,2048]] 16 chatglm /home/ljw/glm-4-9b-chat 1</span><br></pre></td></tr></table></figure>

<p><img src="/2025/01/06/4-%E4%B8%8B%E8%BD%BD%E5%B9%B6%E4%BD%BF%E7%94%A8MindIE%E6%B5%8B%E8%AF%95GLM-4-9B-Chat%E6%A8%A1%E5%9E%8B/2025-01-06-10-43-17-image.png"></p>
<hr>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Jiawei Li"
      src="/uploads/avatar.jpg">
  <p class="site-author-name" itemprop="name">Jiawei Li</p>
  <div class="site-description" itemprop="description">愚蠢的zzz侠</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">14</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jiawei Li</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
